{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "# import labels for the shapes\n",
    "medical_shape_labels = np.genfromtxt('../FiltrationsForGNNs/Medical Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "medical_shape_labels = medical_shape_labels.astype(int)[:,2]\n",
    "print(medical_shape_labels)\n",
    "print(len(medical_shape_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 162 samples.\n",
      "Shape of laplacians: (100, 1000, 1000)\n",
      "Shape of VR persistence images: (100, 100, 100)\n",
      "Shape of abstract persistence images: (100, 100, 100)\n",
      "Shape of selected labels: (100,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 162 # currently set to full dataset\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(len(medical_shape_labels), size=num_samples, replace=False)\n",
    "train_indices = random_indices[:100]\n",
    "validation_indices=random_indices[100:]\n",
    "base = '../FiltrationsForGNNs/Medical Dataset/'\n",
    "#Select the corresponding data and labels\n",
    "medical_laplacians_train = []\n",
    "medical_vr_persistence_images_train = []\n",
    "medical_abstract_persistence_images_train = []\n",
    "medical_selected_labels_train = []\n",
    "\n",
    "for i in train_indices:\n",
    "    medical_laplacians_train.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    medical_vr_persistence_images_train.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_abstract_persistence_images_train.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_selected_labels_train.append(medical_shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "medical_selected_labels_train = np.array(medical_selected_labels_train)\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(medical_laplacians_train).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(medical_vr_persistence_images_train).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(medical_abstract_persistence_images_train).shape}\")\n",
    "print(f\"Shape of selected labels: {medical_selected_labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 162 samples.\n",
      "Shape of laplacians: (62, 1000, 1000)\n",
      "Shape of VR persistence images: (62, 100, 100)\n",
      "Shape of abstract persistence images: (62, 100, 100)\n",
      "Shape of selected labels: (62,)\n"
     ]
    }
   ],
   "source": [
    "medical_laplacians_validation = []\n",
    "medical_vr_persistence_images_validation = []\n",
    "medical_abstract_persistence_images_validation = []\n",
    "medical_selected_labels_validation = []\n",
    "\n",
    "for i in validation_indices:\n",
    "    medical_laplacians_validation.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    medical_vr_persistence_images_validation.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_abstract_persistence_images_validation.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_selected_labels_validation.append(medical_shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "medical_selected_labels_validation = np.array(medical_selected_labels_validation)\n",
    "\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(medical_laplacians_validation).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(medical_vr_persistence_images_validation).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(medical_abstract_persistence_images_validation).shape}\")\n",
    "print(f\"Shape of selected labels: {medical_selected_labels_validation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Adaptive Pooling to resize to 100x100\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((100, 100))\n",
    "        \n",
    "        # Dynamically calculate input size to fc1\n",
    "        self.feature_size = self._get_feature_size(input_shape)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.feature_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_feature_size(self, input_shape):\n",
    "        # Create a dummy input to calculate size after conv and pooling\n",
    "        dummy_input = torch.zeros(1, 1, *input_shape)\n",
    "        x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to get 100x100 size\n",
    "        x = self.adaptive_pool(x)\n",
    "        return x.numel()  # Number of elements after flattening\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to resize to 100x100\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualInputCNN(nn.Module):\n",
    "    def __init__(self, input_shape1, input_shape2, num_classes=2):\n",
    "        super(DualInputCNN, self).__init__()\n",
    "\n",
    "        # Laplacian input path with additional pooling to reduce to 100x100\n",
    "        self.conv1_lap = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_lap = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_lap = nn.MaxPool2d(2, 2)  # Reduce spatial dimensions\n",
    "        self.adaptive_pool_lap = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Persistence image input path (no pooling)\n",
    "        self.conv1_pers = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_pers = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.adaptive_pool_pers = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 100 * 100 + 32 * 100 * 100, 128)  # Adjusted for 100x100 input\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Laplacians path (downsampling to 100x100)\n",
    "        x1 = F.relu(self.conv1_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # First pool: 250x250 -> 125x125\n",
    "        x1 = F.relu(self.conv2_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # Second pool: 125x125 -> 62x62\n",
    "        x1 = self.adaptive_pool_lap(x1)  # Resize to 100x100\n",
    "        \n",
    "        # Persistence images path (no pooling)\n",
    "        x2 = F.relu(self.conv1_pers(x2))\n",
    "        x2 = F.relu(self.conv2_pers(x2))\n",
    "        x2 = self.adaptive_pool_pers(x2)  # Ensure persistence images are 100x100\n",
    "        \n",
    "        # Concatenate along dim=1 (channels)\n",
    "        x = torch.cat((x1, x2), dim=1)  # Concatenates the outputs along the channel axis\n",
    "\n",
    "        # Flatten for fully connected layer\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_input(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with single input\n",
    "        output = model(data)  # Forward through the single-input model\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        tk0.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def test_single_input(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)  # Forward through the single-input model\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_single_input(data_type, data, labels, input_shape):\n",
    "    # Create dataset and split into train/test sets\n",
    "    dataset = ShapeDataset(data, labels)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        dataset.data, dataset.labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert to custom Dataset format for train and test sets\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.stack(train_data), train_labels)\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.stack(test_data), test_labels)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Define CNN model with input_shape\n",
    "    model = CNN(input_shape=input_shape, num_classes=len(set(labels))).to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "\n",
    "    epoch_results = []\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Training model for {data_type} - Epoch {epoch}/{num_epochs}\")\n",
    "        train_loss, accuracy = train_single_input(model, device, train_dataloader, optimizer, criterion, epoch)\n",
    "        test_loss, accuracy, precision, recall, f1 = test_single_input(model, device, test_dataloader, criterion)\n",
    "\n",
    "        # Store results\n",
    "        epoch_results.append({\n",
    "            'Epoch': epoch,\n",
    "            'Test Loss': test_loss,\n",
    "            'Test Accuracy (%)': accuracy,\n",
    "            'Test Precision (%)': precision * 100,\n",
    "            'Test Recall (%)': recall * 100,\n",
    "            'Test F1 Score': f1\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    print(f\"\\nTesting results for {data_type}:\")\n",
    "    print(epoch_results_df)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_dual_input(data_type, data1, data2, labels, input_shape1, input_shape2):\n",
    "    dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data1]  # Shape [1, 100, 100]\n",
    "    dataset2 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data2]  # Shape [1, 100, 100]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    train_data1, test_data1, train_data2, test_data2, train_labels, test_labels = train_test_split(\n",
    "        dataset1, dataset2, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(train_data1), torch.stack(train_data2), train_labels\n",
    "    )\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(test_data1), torch.stack(test_data2), test_labels\n",
    "    )\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = DualInputCNN(input_shape1=input_shape1, input_shape2=input_shape2, num_classes=len(set(labels))).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_results = []\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Training model for {data_type} - Epoch {epoch}/5\")\n",
    "        \n",
    "        # Training step\n",
    "        train_loss, train_accuracy = train_dual_input(model, device, train_dataloader, optimizer, criterion, epoch)\n",
    "        \n",
    "        # Testing step\n",
    "        test_loss, test_accuracy, precision, recall, f1 = test_dual_input(model, device, test_dataloader, criterion)\n",
    "        \n",
    "        # Storing results\n",
    "        epoch_results.append({\n",
    "            'Epoch': epoch,\n",
    "            'Test Loss': test_loss,\n",
    "            'Test Accuracy (%)': test_accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    print(f\"\\nTesting results for {data_type}:\")\n",
    "    print(epoch_results_df)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dual_input(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for batch_idx, (data1, data2, target) in enumerate(tk0):\n",
    "        data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with dual input\n",
    "        output = model(data1, data2)  # Forward through the dual-input model\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        tk0.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def test_dual_input(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data1, data2, target in test_loader:\n",
    "            data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "            output = model(data1, data2)  # Forward through the dual-input model\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            # Collect all labels and predictions for additional metrics\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Return test loss, accuracy, and additional metrics\n",
    "    return avg_loss, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9ca921b68e4d6297d5f869d2b13be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de3c6da51ed49dab3972fe61fc267b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15c42925c824426a9ab68a9ba7c233a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18c2a22e6db4a6da452c862c9959c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643fa5b0187245f7bc9a6a92463efa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7021f99089e6497fa789b168c0eec126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e8c07800ac4ad89f89816bc5727a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9223b7f11cbd4ccab8a32b2a4c3ec740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22274d1025a84d3c811802df3d757e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d7195494b24a55b86f0fb37f8a1818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing results for Laplacians:\n",
      "   Epoch  Test Loss  Test Accuracy (%)  Test Precision (%)  Test Recall (%)  \\\n",
      "0      1   0.665645               45.0           78.611111             45.0   \n",
      "1      2   0.641405               65.0           42.250000             65.0   \n",
      "2      3   0.484549               65.0           42.250000             65.0   \n",
      "3      4   0.432868               65.0           42.250000             65.0   \n",
      "4      5   0.387218               65.0           42.250000             65.0   \n",
      "5      6   0.345222               65.0           42.250000             65.0   \n",
      "6      7   0.296582               80.0           84.705882             80.0   \n",
      "7      8   0.262442               95.0           95.357143             95.0   \n",
      "8      9   0.252081              100.0          100.000000            100.0   \n",
      "9     10   0.204030              100.0          100.000000            100.0   \n",
      "\n",
      "   Test F1 Score  \n",
      "0       0.369333  \n",
      "1       0.512121  \n",
      "2       0.512121  \n",
      "3       0.512121  \n",
      "4       0.512121  \n",
      "5       0.512121  \n",
      "6       0.773333  \n",
      "7       0.949003  \n",
      "8       1.000000  \n",
      "9       1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Train and test for Laplacians (1000x1000 input)\n",
    "lap = train_and_test_single_input(\"Laplacians\", medical_laplacians_train, medical_selected_labels_train, input_shape=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef62fde223a143808db88e8f49a54cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ce949c03774412996d73aa9485780b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780772ba397c490d884154dc2039c5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c617f84fc987435d919bfa1506562586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a60133e9534cf8b62822f39357846d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 6/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd47d2592e514101be76aad6dfbfb86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 7/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf6d2a02e0a4d6586ece507eb94c7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 8/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad962103eaa547b19ced9b9565f45189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 9/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71fbf3ff2c940bea5be298d26c0e37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 10/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeea263e852c497495516b09c0e60afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing results for Laplacians + VR Persistence Images:\n",
      "   Epoch  Test Loss  Test Accuracy (%)  Precision  Recall  F1 Score\n",
      "0      1  73.238319               65.0   0.422500    0.65  0.512121\n",
      "1      2   7.220216               60.0   0.813333    0.60  0.583838\n",
      "2      3   3.280545               75.0   0.819444    0.75  0.700717\n",
      "3      4   0.115575               95.0   0.953571    0.95  0.949003\n",
      "4      5   0.251940               95.0   0.956250    0.95  0.950667\n",
      "5      6   0.105606              100.0   1.000000    1.00  1.000000\n",
      "6      7   0.064116              100.0   1.000000    1.00  1.000000\n",
      "7      8   0.052204              100.0   1.000000    1.00  1.000000\n",
      "8      9   0.187437               90.0   0.913333    0.90  0.895238\n",
      "9     10   0.125898               95.0   0.956250    0.95  0.950667\n"
     ]
    }
   ],
   "source": [
    "dual_vr = train_and_test_dual_input(\"Laplacians + VR Persistence Images\", medical_laplacians_train, medical_vr_persistence_images_train, medical_selected_labels_train, (1000, 1000), (100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7128264224948a1bb615eb3e6ff644a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfbfa2d0849498282f76aed3e3564d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c72e16c126749789b7391cbbb47ee95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33539da5ed474e49af3e8e346d0abff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ce29410cc34c01b881e58d3724d0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 6/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd76dfe5b7194746af242ef3b0e6277d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 7/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6d496d2c3e4244a7a57e725245b6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 8/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd71e7daa3a4819b1874c6d51d16ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 9/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0287ee230004f7ea0563aa855a42a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 10/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2894e3027a4a8c832d461c7f9817f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing results for Laplacians + Abstract Persistence Images:\n",
      "   Epoch  Test Loss  Test Accuracy (%)  Precision  Recall  F1 Score\n",
      "0      1   7.720898               60.0   0.410526    0.60  0.487500\n",
      "1      2   3.239947               65.0   0.608333    0.65  0.581004\n",
      "2      3   0.751923               75.0   0.744048    0.75  0.745014\n",
      "3      4   0.610184               75.0   0.744048    0.75  0.745014\n",
      "4      5   0.585752               80.0   0.800000    0.80  0.790476\n",
      "5      6   0.673741               65.0   0.608333    0.65  0.581004\n",
      "6      7   0.842980               65.0   0.608333    0.65  0.581004\n",
      "7      8   0.525397               85.0   0.895000    0.85  0.853453\n",
      "8      9   0.669665               65.0   0.608333    0.65  0.581004\n",
      "9     10   0.435691               80.0   0.800000    0.80  0.790476\n"
     ]
    }
   ],
   "source": [
    "dual_AP = train_and_test_dual_input(\"Laplacians + Abstract Persistence Images\", medical_laplacians_train, medical_abstract_persistence_images_train, medical_selected_labels_train, (1000, 1000), (100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_single(model, data):\n",
    "    test_dataloader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "    epoch_results = []\n",
    "    # Testing step\n",
    "    test_loss, test_accuracy, precision, recall, f1 = test_single_input(model, device, test_dataloader, nn.CrossEntropyLoss())\n",
    "\n",
    "\n",
    "    # Storing results\n",
    "    epoch_results.append({\n",
    "    'Test Loss': test_loss,\n",
    "    'Test Accuracy (%)': test_accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    y = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = lap(data)  # Forward through the single-input model\n",
    "            _, predicted = output.max(1)\n",
    "            y.append(predicted)\n",
    "    return epoch_results_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lap = ShapeDataset(medical_laplacians_validation, medical_selected_labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results,output = validation_single(lap, data_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Test Loss  Test Accuracy (%)  Precision    Recall  F1 Score\n",
       " 0   0.215015          93.548387    0.94086  0.935484  0.932854,\n",
       " [tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 1, 0, 1, 0, 1, 1]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0])])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_dual(model, data1, data2, label):\n",
    "    dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data1]  # Shape [1, 100, 100]\n",
    "    dataset2 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data2]  # Shape [1, 100, 100]\n",
    "    labels = torch.tensor(label, dtype=torch.long)\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(dataset1), torch.stack(dataset2), labels\n",
    "    )\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    test_loss, test_accuracy, precision, recall, f1 = test_dual_input(model, device, test_dataloader, nn.CrossEntropyLoss())\n",
    "    epoch_results = []\n",
    "\n",
    "    # Storing results\n",
    "    epoch_results.append({\n",
    "        'Test Loss': test_loss,\n",
    "        'Test Accuracy (%)': test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    y = []\n",
    "    with torch.no_grad():\n",
    "        for data1, data2, target in test_dataloader:\n",
    "            data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "            output = dual_vr(data1, data2)  # Forward through the dual-input model\n",
    "            _, predicted = output.max(1)\n",
    "            y.append(predicted)\n",
    "    return epoch_results_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_vr, output_vr = validation_dual(dual_vr, medical_laplacians_validation, medical_vr_persistence_images_validation, medical_selected_labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Test Loss  Test Accuracy (%)  Precision    Recall  F1 Score\n",
       " 0   0.320115          88.709677    0.91871  0.887097  0.891408,\n",
       " [tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 1, 0, 1, 0, 1, 1]),\n",
       "  tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "          0, 0, 0, 1, 1, 1])])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_vr, output_vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ap, output_ap = validation_dual(dual_AP, medical_laplacians_validation, medical_abstract_persistence_images_validation, medical_selected_labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Test Loss  Test Accuracy (%)  Precision    Recall  F1 Score\n",
       " 0   0.974446          69.354839   0.500264  0.693548   0.58126,\n",
       " [tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ap, output_ap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FiltrationsForGNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
