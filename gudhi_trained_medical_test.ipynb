{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# import labels for gudhi shapes\n",
    "gudhi_shape_labels = np.genfromtxt('Gudhi Shape Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "gudhi_shape_labels = gudhi_shape_labels.astype(int)[:,2]\n",
    "print(len(gudhi_shape_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 2000 samples.\n",
      "Shape of laplacians: (2000, 1000, 1000)\n",
      "Shape of VR persistence images: (2000, 100, 100)\n",
      "Shape of abstract persistence images: (2000, 100, 100)\n",
      "Shape of selected labels: (2000,)\n"
     ]
    }
   ],
   "source": [
    "seed_value = 221\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "num_samples = 2000 # currently set to full dataset\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(len(gudhi_shape_labels), size=num_samples, replace=False)\n",
    "base = 'Gudhi Shape Dataset/'\n",
    "# Select the corresponding data and labels\n",
    "gudhi_laplacians = []\n",
    "gudhi_vr_persistence_images = []\n",
    "gudhi_abstract_persistence_images = []\n",
    "gudhi_selected_labels = []\n",
    "\n",
    "for i in random_indices:\n",
    "    gudhi_laplacians.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_vr_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_abstract_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_selected_labels.append(gudhi_shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "gudhi_selected_labels = np.array(gudhi_selected_labels)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(gudhi_laplacians).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(gudhi_vr_persistence_images).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(gudhi_abstract_persistence_images).shape}\")\n",
    "print(f\"Shape of selected labels: {gudhi_selected_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "# import labels for medical shapes\n",
    "medical_shape_labels = np.genfromtxt('Medical Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "medical_shape_labels = medical_shape_labels.astype(int)[:,2]\n",
    "print(len(medical_shape_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 162 samples.\n",
      "Shape of laplacians: (162, 1000, 1000)\n",
      "Shape of VR persistence images: (162, 100, 100)\n",
      "Shape of abstract persistence images: (162, 100, 100)\n",
      "Shape of selected labels: (162,)\n"
     ]
    }
   ],
   "source": [
    "seed_value = 221\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "num_samples = 162 # currently set to full dataset\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(len(medical_shape_labels), size=num_samples, replace=False)\n",
    "base = 'Medical Dataset/'\n",
    "# Select the corresponding data and labels\n",
    "medical_laplacians = []\n",
    "medical_vr_persistence_images = []\n",
    "medical_abstract_persistence_images = []\n",
    "medical_selected_labels = []\n",
    "\n",
    "for i in random_indices:\n",
    "    medical_laplacians.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    medical_vr_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_abstract_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_selected_labels.append(medical_shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "medical_selected_labels = np.array(medical_selected_labels)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(medical_laplacians).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(medical_vr_persistence_images).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(medical_abstract_persistence_images).shape}\")\n",
    "print(f\"Shape of selected labels: {medical_selected_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacians Train data size: 1600\n",
      "Laplacians Validation data size: 281\n",
      "Laplacians Test data size: 81\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split Gudhi Laplacians\n",
    "train_data_gudhi_laplacians, test_data_gudhi_laplacians, train_labels_gudhi, test_labels_gudhi = train_test_split(\n",
    "    gudhi_laplacians, gudhi_selected_labels, test_size=(1 - train_ratio), random_state=42\n",
    ")\n",
    "valid_data_gudhi_laplacians, test_data_gudhi_laplacians, valid_labels_gudhi, test_labels_gudhi = train_test_split(\n",
    "    test_data_gudhi_laplacians, test_labels_gudhi, test_size=(test_ratio / (valid_ratio + test_ratio)), random_state=42\n",
    ")\n",
    "\n",
    "# Split Medical Laplacians (valid/test split only, since all are used for validation/testing)\n",
    "valid_data_medical_laplacians, test_data_medical_laplacians, valid_labels_medical, test_labels_medical = train_test_split(\n",
    "    medical_laplacians, medical_selected_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets for Laplacians and labels\n",
    "valid_laplacians = valid_data_gudhi_laplacians + valid_data_medical_laplacians\n",
    "valid_labels = np.concatenate((valid_labels_gudhi, valid_labels_medical))\n",
    "\n",
    "# Combine test sets for completeness\n",
    "test_laplacians = test_data_medical_laplacians\n",
    "test_labels = test_labels_medical\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Laplacians Train data size: {len(train_data_gudhi_laplacians)}\")\n",
    "print(f\"Laplacians Validation data size: {len(valid_laplacians)}\")\n",
    "print(f\"Laplacians Test data size: {len(test_laplacians)}\")\n",
    "\n",
    "\n",
    "# Split VR Persistence Images\n",
    "train_data_gudhi_vr_persistence_images, test_data_gudhi_vr_persistence_images, train_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    gudhi_vr_persistence_images, gudhi_selected_labels, test_size=(1 - train_ratio), random_state=42\n",
    ")\n",
    "valid_data_gudhi_vr_persistence_images, test_data_gudhi_vr_persistence_images, valid_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    test_data_gudhi_vr_persistence_images, test_labels_gudhi_check, test_size=(test_ratio / (valid_ratio + test_ratio)), random_state=42\n",
    ")\n",
    "\n",
    "# Split Medical VR Persistence Images (valid/test split only, since all are used for validation/testing)\n",
    "valid_data_medical_vr_persistence_images, test_data_medical_vr_persistence_images, valid_labels_medical_check, test_labels_medical_check = train_test_split(\n",
    "    medical_vr_persistence_images, medical_selected_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets for VR Persistence Images and labels\n",
    "valid_vr_persistence_images = valid_data_gudhi_vr_persistence_images + valid_data_medical_vr_persistence_images\n",
    "valid_vr_labels = np.concatenate((valid_labels_gudhi, valid_labels_medical))\n",
    "\n",
    "# Combine test sets for VR Persistence Images and labels\n",
    "test_vr_persistence_images = test_data_medical_vr_persistence_images\n",
    "test_vr_labels = test_labels_medical\n",
    "\n",
    "\n",
    "# Split Abstract Persistence Images\n",
    "train_data_gudhi_abstract_persistence_images, test_data_gudhi_abstract_persistence_images, train_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    gudhi_abstract_persistence_images, gudhi_selected_labels, test_size=(1 - train_ratio), random_state=42\n",
    ")\n",
    "valid_data_gudhi_abstract_persistence_images, test_data_gudhi_abstract_persistence_images, valid_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    test_data_gudhi_abstract_persistence_images, test_labels_gudhi_check, test_size=(test_ratio / (valid_ratio + test_ratio)), random_state=42\n",
    ")\n",
    "\n",
    "# Split Medical Abstract Persistence Images (valid/test split only, since all are used for validation/testing)\n",
    "valid_data_medical_abstract_persistence_images, test_data_medical_abstract_persistence_images, valid_labels_medical_check, test_labels_medical_check = train_test_split(\n",
    "    medical_abstract_persistence_images, medical_selected_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets for Abstract Persistence Images and labels\n",
    "valid_abstract_persistence_images = valid_data_gudhi_abstract_persistence_images + valid_data_medical_abstract_persistence_images\n",
    "valid_abstract_labels = np.concatenate((valid_labels_gudhi, valid_labels_medical))\n",
    "\n",
    "# Combine test sets for Abstract Persistence Images and labels\n",
    "test_abstract_persistence_images = test_data_medical_abstract_persistence_images\n",
    "test_abstract_labels = test_labels_medical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Adaptive Pooling to resize to 100x100\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((100, 100))\n",
    "        \n",
    "        # Dynamically calculate input size to fc1\n",
    "        self.feature_size = self._get_feature_size(input_shape)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.feature_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_feature_size(self, input_shape):\n",
    "        # Create a dummy input to calculate size after conv and pooling\n",
    "        dummy_input = torch.zeros(1, 1, *input_shape)\n",
    "        x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to get 100x100 size\n",
    "        x = self.adaptive_pool(x)\n",
    "        return x.numel()  # Number of elements after flattening\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to resize to 100x100\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class DualInputCNN(nn.Module):\n",
    "    def __init__(self, input_shape1, input_shape2, num_classes=2):\n",
    "        super(DualInputCNN, self).__init__()\n",
    "\n",
    "        # Laplacian input path with additional pooling to reduce to 100x100\n",
    "        self.conv1_lap = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_lap = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_lap = nn.MaxPool2d(2, 2)  # Reduce spatial dimensions\n",
    "        self.adaptive_pool_lap = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Persistence image input path (no pooling)\n",
    "        self.conv1_pers = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_pers = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.adaptive_pool_pers = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 100 * 100 + 32 * 100 * 100, 128)  # Adjusted for 100x100 input\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Laplacians path (downsampling to 100x100)\n",
    "        x1 = F.relu(self.conv1_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # First pool: 250x250 -> 125x125\n",
    "        x1 = F.relu(self.conv2_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # Second pool: 125x125 -> 62x62\n",
    "        x1 = self.adaptive_pool_lap(x1)  # Resize to 100x100\n",
    "        \n",
    "        # Persistence images path (no pooling)\n",
    "        x2 = F.relu(self.conv1_pers(x2))\n",
    "        x2 = F.relu(self.conv2_pers(x2))\n",
    "        x2 = self.adaptive_pool_pers(x2)  # Ensure persistence images are 100x100\n",
    "        \n",
    "        # Concatenate along dim=1 (channels)\n",
    "        x = torch.cat((x1, x2), dim=1)  # Concatenates the outputs along the channel axis\n",
    "\n",
    "        # Flatten for fully connected layer\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch Datasets\n",
    "test_dataset_laplacians = ShapeDataset(test_laplacians, test_labels)\n",
    "test_dataset_vr = ShapeDataset(test_vr_persistence_images, test_vr_labels)\n",
    "test_dataset_abstract = ShapeDataset(test_abstract_persistence_images, test_abstract_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "test_loader_laplacians = torch.utils.data.DataLoader(test_dataset_laplacians, batch_size=batch_size, shuffle=False)\n",
    "test_loader_vr = torch.utils.data.DataLoader(test_dataset_vr, batch_size=batch_size, shuffle=False)\n",
    "test_loader_abstract = torch.utils.data.DataLoader(test_dataset_abstract, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d3/99lvl9fd1673ngz9966pvq100000gn/T/ipykernel_6943/705805221.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{model_name}.pth\"))\n",
      "/var/folders/d3/99lvl9fd1673ngz9966pvq100000gn/T/ipykernel_6943/705805221.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_vr.load_state_dict(torch.load(f\"{model_name_vr}.pth\"))\n",
      "/var/folders/d3/99lvl9fd1673ngz9966pvq100000gn/T/ipykernel_6943/705805221.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_abstract.load_state_dict(torch.load(f\"{model_name_abstract}.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# For single-input CNN (Laplacians)\n",
    "input_shape = train_data_gudhi_laplacians[0].shape\n",
    "num_classes = 2  # binary classification\n",
    "num_epochs = 10\n",
    "\n",
    "# Create and manage single-input CNN models\n",
    "models_single_laplacians = {}\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model_name = f\"Trained CNNs/model_single_laplacians_epoch_{epoch}\"\n",
    "    model = CNN(input_shape, num_classes)\n",
    "    model.load_state_dict(torch.load(f\"{model_name}.pth\"))\n",
    "    model.eval()\n",
    "    models_single_laplacians[epoch] = model\n",
    "\n",
    "\n",
    "# For dual-input CNNs (Laplacians + VR Persistence Images, Laplacians + Abstract Persistence Images)\n",
    "input_shape1 = train_data_gudhi_laplacians[0].shape\n",
    "input_shape2 = train_data_gudhi_vr_persistence_images[0].shape\n",
    "input_shape3 = train_data_gudhi_abstract_persistence_images[0].shape\n",
    "\n",
    "# Manage dual-input CNNs for VR and Abstract datasets\n",
    "models_dual_lap_vr = {}\n",
    "models_dual_lap_abstract = {}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Laplacians + VR\n",
    "    model_name_vr = f\"Trained CNNs/model_dual_lap_vr_epoch_{epoch}\"\n",
    "    model_vr = DualInputCNN(input_shape1, input_shape2, num_classes)\n",
    "    model_vr.load_state_dict(torch.load(f\"{model_name_vr}.pth\"))\n",
    "    model_vr.eval()\n",
    "    models_dual_lap_vr[epoch] = model_vr\n",
    "\n",
    "    # Laplacians + Abstract\n",
    "    model_name_abstract = f\"Trained CNNs/model_dual_lap_abstract_epoch_{epoch}\"\n",
    "    model_abstract = DualInputCNN(input_shape1, input_shape3, num_classes)\n",
    "    model_abstract.load_state_dict(torch.load(f\"{model_name_abstract}.pth\"))\n",
    "    model_abstract.eval()\n",
    "    models_dual_lap_abstract[epoch] = model_abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_input(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(dataloader, desc=\"Testing\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Loss': [avg_loss],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1]\n",
    "    })\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    return metrics_df, cm\n",
    "\n",
    "\n",
    "def test_dual_input(model, dataloader1, dataloader2, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(zip(dataloader1, dataloader2), desc=\"Testing (Dual Input)\", leave=False, total=min(len(dataloader1), len(dataloader2)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs1, _), (inputs2, targets) in progress_bar:\n",
    "            inputs1, inputs2, targets = inputs1.to(device), inputs2.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs1, inputs2)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if outputs.shape[-1] > 1:\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            else:  # Binary classification\n",
    "                predicted = (outputs > 0.5).float()\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader1.dataset)\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Loss': [avg_loss],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1]\n",
    "    })\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    return metrics_df, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39338671b4041859eb32614dbd5b103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1669, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00263771c2314c08a9986436741bcdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1035, Test Accuracy: 0.3827, Precision: 0.3600, Recall: 0.9310, F1 Score: 0.5192\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a004cd77d949af9e91c448c7aa7ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4314, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 2 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be77fe8586b4d05940e71da51fa1fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3492, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59365d2106ae4be48b881fb73563f0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1564, Test Accuracy: 0.3457, Precision: 0.3500, Recall: 0.9655, F1 Score: 0.5138\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e4d3aa98924f0398b09a816ffe05fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3393, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 3 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21848d26d16443f18428f6262e359c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3931, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d4bccd1da5455db2bb8d39666d10aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2216, Test Accuracy: 0.3457, Precision: 0.3500, Recall: 0.9655, F1 Score: 0.5138\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0646c0a9c5ca4f7caf7f50f6f9f3ea18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2476, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 4 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d4af72c0e64e199a4a0846b3dd7087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4346, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b353b8ed004d639f37aa2d7f71f4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2160, Test Accuracy: 0.3457, Precision: 0.3500, Recall: 0.9655, F1 Score: 0.5138\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1204426f2db64beab3e1e2b1990b2367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2746, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 5 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b849efb4904a85bfbc2f4c4989b749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4183, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a01b1bfa0942cab4d50f75363d23d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2340, Test Accuracy: 0.3457, Precision: 0.3500, Recall: 0.9655, F1 Score: 0.5138\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7030b8bf2fd44f548f1dc1b302a74b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2377, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 6 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a3e406b1fa4ca6801a77cdfaf15e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5482, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26070ffbb7840db82230bc724a80fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2114, Test Accuracy: 0.3457, Precision: 0.3500, Recall: 0.9655, F1 Score: 0.5138\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5289e1f157cf4574bcf6b53ce8a7bb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2757, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 7 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0f61e9a940487dac2a7e8563bb2a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4895, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5769cda9eb249b1add1030e107a2475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1885, Test Accuracy: 0.3457, Precision: 0.3500, Recall: 0.9655, F1 Score: 0.5138\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c33fd9db4b44b180d143a6106bf229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2991, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 8 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dde92591c304e36883f4b2c5985000e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5501, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabd3b706ad54dd596bd93ab01bf7923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2252, Test Accuracy: 0.3333, Precision: 0.3418, Recall: 0.9310, F1 Score: 0.5000\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e0db75f5a644c5ae64e0ac8afdc48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3061, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 9 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fc18b8eaa4473c989189cdb8f4a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5789, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3738f9eb3344527ba05ec6c68088de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2074, Test Accuracy: 0.3210, Precision: 0.3333, Recall: 0.8966, F1 Score: 0.4860\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8dfe5833bb498e9cce544f06df236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3622, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Epoch 10 / 10\n",
      "Testing Single Input Model (Laplacians)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5722ad4ae8364492a23fd0f45da7cf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6833, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n",
      "Testing Dual Input Model (Laplacians + VR Persistence Images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ed172f847a4493b471fa5477f959ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1736, Test Accuracy: 0.3704, Precision: 0.3472, Recall: 0.8621, F1 Score: 0.4950\n",
      "Testing Dual Input Model (Laplacians + Abstract Persistence Images)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d78b6587469420a8b7f32505675d3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3801, Test Accuracy: 0.6420, Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/FiltrationsForGNNsLargeData/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store all metrics for each epoch\n",
    "test_metrics_single_list = []\n",
    "test_metrics_dual_vr_list = []\n",
    "test_metrics_dual_abstract_list = []\n",
    "\n",
    "# Initialize empty lists to store all confusion matrices for each epoch\n",
    "cm_single_list = []\n",
    "cm_dual_vr_list = []\n",
    "cm_dual_abstract_list = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):  # Start from 1 since epochs in the dictionaries are 1-indexed\n",
    "    print(f\"Epoch {epoch} / {num_epochs}\")\n",
    "\n",
    "    # Access the models for the current epoch\n",
    "    print(\"Testing Single Input Model (Laplacians)\")\n",
    "    model_single = models_single_laplacians[epoch]\n",
    "    test_metrics_single, cm_single = test_single_input(model_single, test_loader_laplacians, criterion, device)\n",
    "    test_metrics_single_list.append(test_metrics_single)\n",
    "    cm_single_list.append(cm_single)\n",
    "\n",
    "    print(\"Testing Dual Input Model (Laplacians + VR Persistence Images)\")\n",
    "    model_dual_vr = models_dual_lap_vr[epoch]\n",
    "    test_metrics_dual_vr, cm_dual_vr = test_dual_input(\n",
    "        model_dual_vr, test_loader_laplacians, test_loader_vr, criterion, device\n",
    "    )\n",
    "    test_metrics_dual_vr_list.append(test_metrics_dual_vr)\n",
    "    cm_dual_vr_list.append(cm_dual_vr)\n",
    "\n",
    "    print(\"Testing Dual Input Model (Laplacians + Abstract Persistence Images)\")\n",
    "    model_dual_abstract = models_dual_lap_abstract[epoch]\n",
    "    test_metrics_dual_abstract, cm_dual_abstract = test_dual_input(\n",
    "        model_dual_abstract, test_loader_laplacians, test_loader_abstract, criterion, device\n",
    "    )\n",
    "    test_metrics_dual_abstract_list.append(test_metrics_dual_abstract)\n",
    "    cm_dual_abstract_list.append(cm_dual_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single-input model (Laplacians) Test Metrics:\n",
      "       Test Loss  Test Accuracy  Precision  Recall  F1 Score\n",
      "Epoch                                                       \n",
      "1       0.166900       0.641975        0.0     0.0       0.0\n",
      "2       0.349204       0.641975        0.0     0.0       0.0\n",
      "3       0.393054       0.641975        0.0     0.0       0.0\n",
      "4       0.434565       0.641975        0.0     0.0       0.0\n",
      "5       0.418305       0.641975        0.0     0.0       0.0\n",
      "6       0.548175       0.641975        0.0     0.0       0.0\n",
      "7       0.489510       0.641975        0.0     0.0       0.0\n",
      "8       0.550089       0.641975        0.0     0.0       0.0\n",
      "9       0.578930       0.641975        0.0     0.0       0.0\n",
      "10      0.683307       0.641975        0.0     0.0       0.0\n",
      "\n",
      "Dual-input model (Laplacians + VR Persistence Images) Test Metrics:\n",
      "       Test Loss  Test Accuracy  Precision    Recall  F1 Score\n",
      "Epoch                                                         \n",
      "1       0.103481       0.382716   0.360000  0.931034  0.519231\n",
      "2       0.156395       0.345679   0.350000  0.965517  0.513761\n",
      "3       0.221590       0.345679   0.350000  0.965517  0.513761\n",
      "4       0.216004       0.345679   0.350000  0.965517  0.513761\n",
      "5       0.234015       0.345679   0.350000  0.965517  0.513761\n",
      "6       0.211394       0.345679   0.350000  0.965517  0.513761\n",
      "7       0.188501       0.345679   0.350000  0.965517  0.513761\n",
      "8       0.225156       0.333333   0.341772  0.931034  0.500000\n",
      "9       0.207412       0.320988   0.333333  0.896552  0.485981\n",
      "10      0.173573       0.370370   0.347222  0.862069  0.495050\n",
      "\n",
      "Dual-input model (Laplacians + Abstract Persistence Images) Test Metrics:\n",
      "       Test Loss  Test Accuracy  Precision  Recall  F1 Score\n",
      "Epoch                                                       \n",
      "1       0.431430       0.641975        0.0     0.0       0.0\n",
      "2       0.339308       0.641975        0.0     0.0       0.0\n",
      "3       0.247576       0.641975        0.0     0.0       0.0\n",
      "4       0.274599       0.641975        0.0     0.0       0.0\n",
      "5       0.237708       0.641975        0.0     0.0       0.0\n",
      "6       0.275737       0.641975        0.0     0.0       0.0\n",
      "7       0.299068       0.641975        0.0     0.0       0.0\n",
      "8       0.306126       0.641975        0.0     0.0       0.0\n",
      "9       0.362205       0.641975        0.0     0.0       0.0\n",
      "10      0.380150       0.641975        0.0     0.0       0.0\n"
     ]
    }
   ],
   "source": [
    "# Convert the lists of metrics into DataFrames with epoch as the index\n",
    "test_metrics_single_df = pd.concat(test_metrics_single_list, ignore_index=True)\n",
    "test_metrics_dual_vr_df = pd.concat(test_metrics_dual_vr_list, ignore_index=True)\n",
    "test_metrics_dual_abstract_df = pd.concat(test_metrics_dual_abstract_list, ignore_index=True)\n",
    "\n",
    "# Add 'Epoch' as new column\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "\n",
    "test_metrics_single_df['Epoch'] = epochs\n",
    "test_metrics_dual_vr_df['Epoch'] = epochs\n",
    "test_metrics_dual_abstract_df['Epoch'] = epochs\n",
    "\n",
    "# Set 'Epoch' as index\n",
    "test_metrics_single_df.set_index('Epoch', inplace=True)\n",
    "test_metrics_dual_vr_df.set_index('Epoch', inplace=True)\n",
    "test_metrics_dual_abstract_df.set_index('Epoch', inplace=True)\n",
    "\n",
    "# Rename first two columns to 'Test Loss' and 'Test Accuracy'\n",
    "test_metrics_single_df.rename(columns={'Loss': 'Test Loss', 'Accuracy': 'Test Accuracy'}, inplace=True)\n",
    "test_metrics_dual_vr_df.rename(columns={'Loss': 'Test Loss', 'Accuracy': 'Test Accuracy'}, inplace=True)\n",
    "test_metrics_dual_abstract_df.rename(columns={'Loss': 'Test Loss', 'Accuracy': 'Test Accuracy'}, inplace=True)\n",
    "\n",
    "# Print final test metrics for all models\n",
    "print(\"\\nSingle-input model (Laplacians) Test Metrics:\")\n",
    "print(test_metrics_single_df)\n",
    "\n",
    "print(\"\\nDual-input model (Laplacians + VR Persistence Images) Test Metrics:\")\n",
    "print(test_metrics_dual_vr_df)\n",
    "\n",
    "print(\"\\nDual-input model (Laplacians + Abstract Persistence Images) Test Metrics:\")\n",
    "print(test_metrics_dual_abstract_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test metrics to CSV files\n",
    "\n",
    "test_metrics_single_df.to_csv('test_metrics_single_laplacian_medical.csv')\n",
    "test_metrics_dual_vr_df.to_csv('test_metrics_dual_lap_vr_medical.csv')\n",
    "test_metrics_dual_abstract_df.to_csv('test_metrics_dual_lap_abstract_medical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and export confusion matrices to \"Confusion\\ Matrices/\" folder\n",
    "\n",
    "# Single-input model (Laplacians)\n",
    "for i, cm in enumerate(cm_single_list):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 14})\n",
    "    plt.title(f\"Confusion Matrix - Single-input Model (Laplacians), Epoch {i+1}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"Confusion Matrices/single_laplacians_cm_epoch_{i+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Dual-input model (Laplacians + VR Persistence Images)\n",
    "for i, cm in enumerate(cm_dual_vr_list):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 14})\n",
    "    plt.title(f\"Confusion Matrix - Dual-input Model (Laplacians + VR Persistence Images), Epoch {i+1}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"Confusion Matrices/dual_lap_vr_cm_epoch_{i+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Dual-input model (Laplacians + Abstract Persistence Images)\n",
    "for i, cm in enumerate(cm_dual_abstract_list):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 14})\n",
    "    plt.title(f\"Confusion Matrix - Dual-input Model (Laplacians + Abstract Persistence Images), Epoch {i+1}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"Confusion Matrices/dual_lap_abstract_cm_epoch_{i+1}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FiltrationsForGNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
