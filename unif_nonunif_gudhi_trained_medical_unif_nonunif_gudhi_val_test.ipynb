{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacakge & Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# import labels for gudhi shapes\n",
    "gudhi_shape_labels_unif = np.genfromtxt('Gudhi Shape Dataset Uniform/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "gudhi_shape_labels_unif = gudhi_shape_labels_unif.astype(int)[:,2]\n",
    "print(len(gudhi_shape_labels_unif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d3/99lvl9fd1673ngz9966pvq100000gn/T/ipykernel_59957/2240478565.py:3: RuntimeWarning: invalid value encountered in cast\n",
      "  gudhi_shape_labels_nonunif = gudhi_shape_labels_nonunif.astype(int)[:,2]\n"
     ]
    }
   ],
   "source": [
    "# import labels for gudhi shapes\n",
    "gudhi_shape_labels_nonunif = np.genfromtxt('Gudhi Shape Dataset Nonuniform/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "gudhi_shape_labels_nonunif = gudhi_shape_labels_nonunif.astype(int)[:,2]\n",
    "print(len(gudhi_shape_labels_nonunif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi_shapes_nonunif = np.array([])\n",
    "\n",
    "base = 'Gudhi Shape Dataset Nonuniform'\n",
    "\n",
    "# Check if the required files exist for each shape\n",
    "for i in range(1000, 4769):\n",
    "    points_file = f'{base}/shape_{i}_points.csv'\n",
    "    laplacian_file = f'{base}/shape_{i}_laplacian.csv'\n",
    "    vr_persistence_image_file = f'{base}/shape_{i}_vr_persistence_image.csv'\n",
    "    abstract_persistence_image_file = f'{base}/shape_{i}_abstract_persistence_image.csv'\n",
    "\n",
    "    if (os.path.exists(points_file) and\n",
    "        os.path.exists(laplacian_file) and\n",
    "        os.path.exists(vr_persistence_image_file) and\n",
    "        os.path.exists(abstract_persistence_image_file)):\n",
    "        gudhi_shapes_nonunif = np.append(gudhi_shapes_nonunif, i)\n",
    "    \n",
    "\n",
    "gudhi_shapes_nonunif = gudhi_shapes_nonunif.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 1000 samples.\n",
      "Shape of laplacians: (1000, 1000, 1000)\n",
      "Shape of VR persistence images: (1000, 100, 100)\n",
      "Shape of abstract persistence images: (1000, 100, 100)\n",
      "Shape of selected labels: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Uniform\n",
    "\n",
    "seed_value = 221\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "num_samples_unif = len(gudhi_shape_labels_unif) # currently set to full dataset\n",
    "num_samples_unif = 1000\n",
    "\n",
    "# Generate random indices\n",
    "random_indices_unif = np.random.choice(len(gudhi_shape_labels_unif), size=num_samples_unif, replace=False)\n",
    "base = 'Gudhi Shape Dataset Uniform'\n",
    "# Select the corresponding data and labels\n",
    "gudhi_laplacians_unif = []\n",
    "gudhi_vr_persistence_images_unif = []\n",
    "gudhi_abstract_persistence_images_unif = []\n",
    "gudhi_selected_labels_unif = []\n",
    "\n",
    "for i in random_indices_unif:\n",
    "    gudhi_laplacians_unif.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_vr_persistence_images_unif.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_abstract_persistence_images_unif.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_selected_labels_unif.append(gudhi_shape_labels_unif[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "gudhi_selected_labels_unif = np.array(gudhi_selected_labels_unif)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Randomly selected {num_samples_unif} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(gudhi_laplacians_unif).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(gudhi_vr_persistence_images_unif).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(gudhi_abstract_persistence_images_unif).shape}\")\n",
    "print(f\"Shape of selected labels: {gudhi_selected_labels_unif.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 1000 samples.\n",
      "Shape of laplacians: (1000, 1000, 1000)\n",
      "Shape of VR persistence images: (1000, 100, 100)\n",
      "Shape of abstract persistence images: (1000, 100, 100)\n",
      "Shape of selected labels: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Non-uniform\n",
    "\n",
    "seed_value = 221\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "num_samples_nonunif = len(gudhi_shapes_nonunif) # currently set to full dataset\n",
    "num_samples_nonunif = 1000\n",
    "\n",
    "# Generate random indices\n",
    "random_indices_nonunif = np.random.choice(len(gudhi_shapes_nonunif), size=num_samples_nonunif, replace=False)\n",
    "base = 'Gudhi Shape Dataset Nonuniform'\n",
    "# Select the corresponding data and labels\n",
    "gudhi_laplacians_nonunif = []\n",
    "gudhi_vr_persistence_images_nonunif = []\n",
    "gudhi_abstract_persistence_images_nonunif = []\n",
    "gudhi_selected_labels_nonunif = []\n",
    "\n",
    "for i in random_indices_nonunif:\n",
    "    gudhi_laplacians_nonunif.append(np.genfromtxt(f'{base}/shape_{gudhi_shapes_nonunif[i]}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_vr_persistence_images_nonunif.append(np.genfromtxt(f'{base}/shape_{gudhi_shapes_nonunif[i]}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_abstract_persistence_images_nonunif.append(np.genfromtxt(f'{base}/shape_{gudhi_shapes_nonunif[i]}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    gudhi_selected_labels_nonunif.append(gudhi_shape_labels_nonunif[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "gudhi_selected_labels_nonunif = np.array(gudhi_selected_labels_nonunif)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Randomly selected {num_samples_nonunif} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(gudhi_laplacians_nonunif).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(gudhi_vr_persistence_images_nonunif).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(gudhi_abstract_persistence_images_nonunif).shape}\")\n",
    "print(f\"Shape of selected labels: {gudhi_selected_labels_nonunif.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi_laplacians = np.concatenate((gudhi_laplacians_nonunif, gudhi_laplacians_unif), axis=0)\n",
    "gudhi_vr_persistence_images = np.concatenate((gudhi_vr_persistence_images_nonunif, gudhi_vr_persistence_images_unif), axis=0)\n",
    "gudhi_abstract_persistence_images = np.concatenate((gudhi_abstract_persistence_images_nonunif, gudhi_abstract_persistence_images_unif), axis=0)\n",
    "gudhi_selected_labels = np.concatenate((gudhi_selected_labels_nonunif, gudhi_selected_labels_unif), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined laplacians: (2000, 1000, 1000)\n",
      "Shape of combined VR persistence images: (2000, 100, 100)\n",
      "Shape of combined abstract persistence images: (2000, 100, 100)\n",
      "Shape of combined selected labels: (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of combined laplacians: {gudhi_laplacians.shape}\")\n",
    "print(f\"Shape of combined VR persistence images: {gudhi_vr_persistence_images.shape}\")\n",
    "print(f\"Shape of combined abstract persistence images: {gudhi_abstract_persistence_images.shape}\")\n",
    "print(f\"Shape of combined selected labels: {gudhi_selected_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "# import labels for medical shapes\n",
    "medical_shape_labels = np.genfromtxt('Medical Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "medical_shape_labels = medical_shape_labels.astype(int)[:,2]\n",
    "print(len(medical_shape_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 162 samples.\n",
      "Shape of laplacians: (162, 1000, 1000)\n",
      "Shape of VR persistence images: (162, 100, 100)\n",
      "Shape of abstract persistence images: (162, 100, 100)\n",
      "Shape of selected labels: (162,)\n"
     ]
    }
   ],
   "source": [
    "seed_value = 221\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "num_samples = 162 # currently set to full dataset\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(len(medical_shape_labels), size=num_samples, replace=False)\n",
    "base = 'Medical Dataset/'\n",
    "# Select the corresponding data and labels\n",
    "medical_laplacians = []\n",
    "medical_vr_persistence_images = []\n",
    "medical_abstract_persistence_images = []\n",
    "medical_selected_labels = []\n",
    "\n",
    "for i in random_indices:\n",
    "    medical_laplacians.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    medical_vr_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_abstract_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_selected_labels.append(medical_shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "medical_selected_labels = np.array(medical_selected_labels)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(medical_laplacians).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(medical_vr_persistence_images).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(medical_abstract_persistence_images).shape}\")\n",
    "print(f\"Shape of selected labels: {medical_selected_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacians Train data size: 1600\n",
      "Laplacians Validation data size: 281\n",
      "Laplacians Test data size: 281\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split Gudhi Laplacians\n",
    "train_data_gudhi_laplacians, test_data_gudhi_laplacians, train_labels_gudhi, test_labels_gudhi = train_test_split(\n",
    "    gudhi_laplacians, gudhi_selected_labels, test_size=(1 - train_ratio), random_state=42\n",
    ")\n",
    "valid_data_gudhi_laplacians, test_data_gudhi_laplacians, valid_labels_gudhi, test_labels_gudhi = train_test_split(\n",
    "    test_data_gudhi_laplacians, test_labels_gudhi, test_size=(test_ratio / (valid_ratio + test_ratio)), random_state=42\n",
    ")\n",
    "\n",
    "# Split Medical Laplacians (valid/test split only, since all are used for validation/testing)\n",
    "valid_data_medical_laplacians, test_data_medical_laplacians, valid_labels_medical, test_labels_medical = train_test_split(\n",
    "    medical_laplacians, medical_selected_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets for Laplacians and labels\n",
    "valid_laplacians = np.concatenate((valid_data_gudhi_laplacians, valid_data_medical_laplacians), axis=0)\n",
    "valid_labels = np.concatenate((valid_labels_gudhi, valid_labels_medical))\n",
    "\n",
    "# Combine test sets for completeness\n",
    "test_laplacians = np.concatenate((test_data_gudhi_laplacians, test_data_medical_laplacians), axis=0)\n",
    "test_labels = np.concatenate((test_labels_gudhi, test_labels_medical))\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Laplacians Train data size: {len(train_data_gudhi_laplacians)}\")\n",
    "print(f\"Laplacians Validation data size: {len(valid_laplacians)}\")\n",
    "print(f\"Laplacians Test data size: {len(test_laplacians)}\")\n",
    "\n",
    "\n",
    "# Split VR Persistence Images\n",
    "train_data_gudhi_vr_persistence_images, test_data_gudhi_vr_persistence_images, train_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    gudhi_vr_persistence_images, gudhi_selected_labels, test_size=(1 - train_ratio), random_state=42\n",
    ")\n",
    "valid_data_gudhi_vr_persistence_images, test_data_gudhi_vr_persistence_images, valid_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    test_data_gudhi_vr_persistence_images, test_labels_gudhi_check, test_size=(test_ratio / (valid_ratio + test_ratio)), random_state=42\n",
    ")\n",
    "\n",
    "# Split Medical VR Persistence Images (valid/test split only, since all are used for validation/testing)\n",
    "valid_data_medical_vr_persistence_images, test_data_medical_vr_persistence_images, valid_labels_medical_check, test_labels_medical_check = train_test_split(\n",
    "    medical_vr_persistence_images, medical_selected_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets for VR Persistence Images and labels\n",
    "valid_vr_persistence_images = np.concatenate((valid_data_gudhi_vr_persistence_images, valid_data_medical_vr_persistence_images), axis=0)\n",
    "valid_vr_labels = np.concatenate((valid_labels_gudhi, valid_labels_medical))\n",
    "\n",
    "# Combine test sets for VR Persistence Images and labels\n",
    "test_vr_persistence_images = np.concatenate((test_data_gudhi_vr_persistence_images, test_data_medical_vr_persistence_images), axis=0)\n",
    "test_vr_labels = np.concatenate((test_labels_gudhi, test_labels_medical))\n",
    "\n",
    "\n",
    "# Split Abstract Persistence Images\n",
    "train_data_gudhi_abstract_persistence_images, test_data_gudhi_abstract_persistence_images, train_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    gudhi_abstract_persistence_images, gudhi_selected_labels, test_size=(1 - train_ratio), random_state=42\n",
    ")\n",
    "valid_data_gudhi_abstract_persistence_images, test_data_gudhi_abstract_persistence_images, valid_labels_gudhi_check, test_labels_gudhi_check = train_test_split(\n",
    "    test_data_gudhi_abstract_persistence_images, test_labels_gudhi_check, test_size=(test_ratio / (valid_ratio + test_ratio)), random_state=42\n",
    ")\n",
    "\n",
    "# Split Medical Abstract Persistence Images (valid/test split only, since all are used for validation/testing)\n",
    "valid_data_medical_abstract_persistence_images, test_data_medical_abstract_persistence_images, valid_labels_medical_check, test_labels_medical_check = train_test_split(\n",
    "    medical_abstract_persistence_images, medical_selected_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets for Abstract Persistence Images and labels\n",
    "valid_abstract_persistence_images = np.concatenate((valid_data_gudhi_abstract_persistence_images, valid_data_medical_abstract_persistence_images), axis=0)\n",
    "valid_abstract_labels = np.concatenate((valid_labels_gudhi, valid_labels_medical))\n",
    "\n",
    "# Combine test sets for Abstract Persistence Images and labels\n",
    "test_abstract_persistence_images = np.concatenate((test_data_gudhi_abstract_persistence_images, test_data_medical_abstract_persistence_images), axis=0)\n",
    "test_abstract_labels = np.concatenate((test_labels_gudhi, test_labels_medical))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1000, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_gudhi_laplacians.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Adaptive Pooling to resize to 100x100\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((100, 100))\n",
    "        \n",
    "        # Dynamically calculate input size to fc1\n",
    "        self.feature_size = self._get_feature_size(input_shape)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.feature_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_feature_size(self, input_shape):\n",
    "        # Create a dummy input to calculate size after conv and pooling\n",
    "        dummy_input = torch.zeros(1, 1, *input_shape)\n",
    "        x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to get 100x100 size\n",
    "        x = self.adaptive_pool(x)\n",
    "        return x.numel()  # Number of elements after flattening\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to resize to 100x100\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualInputCNN(nn.Module):\n",
    "    def __init__(self, input_shape1, input_shape2, num_classes=2):\n",
    "        super(DualInputCNN, self).__init__()\n",
    "\n",
    "        # Laplacian input path with additional pooling to reduce to 100x100\n",
    "        self.conv1_lap = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_lap = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_lap = nn.MaxPool2d(2, 2)  # Reduce spatial dimensions\n",
    "        self.adaptive_pool_lap = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Persistence image input path (no pooling)\n",
    "        self.conv1_pers = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_pers = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.adaptive_pool_pers = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 100 * 100 + 32 * 100 * 100, 128)  # Adjusted for 100x100 input\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Laplacians path (downsampling to 100x100)\n",
    "        x1 = F.relu(self.conv1_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # First pool: 250x250 -> 125x125\n",
    "        x1 = F.relu(self.conv2_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # Second pool: 125x125 -> 62x62\n",
    "        x1 = self.adaptive_pool_lap(x1)  # Resize to 100x100\n",
    "        \n",
    "        # Persistence images path (no pooling)\n",
    "        x2 = F.relu(self.conv1_pers(x2))\n",
    "        x2 = F.relu(self.conv2_pers(x2))\n",
    "        x2 = self.adaptive_pool_pers(x2)  # Ensure persistence images are 100x100\n",
    "        \n",
    "        # Concatenate along dim=1 (channels)\n",
    "        x = torch.cat((x1, x2), dim=1)  # Concatenates the outputs along the channel axis\n",
    "\n",
    "        # Flatten for fully connected layer\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch Datasets\n",
    "train_dataset_laplacians = ShapeDataset(train_data_gudhi_laplacians, train_labels_gudhi)\n",
    "valid_dataset_laplacians = ShapeDataset(valid_laplacians, valid_labels)\n",
    "test_dataset_laplacians = ShapeDataset(test_laplacians, test_labels)\n",
    "\n",
    "train_dataset_vr = ShapeDataset(train_data_gudhi_vr_persistence_images, train_labels_gudhi)\n",
    "valid_dataset_vr = ShapeDataset(valid_vr_persistence_images, valid_vr_labels)\n",
    "test_dataset_vr = ShapeDataset(test_vr_persistence_images, test_vr_labels)\n",
    "\n",
    "train_dataset_abstract = ShapeDataset(train_data_gudhi_abstract_persistence_images, train_labels_gudhi)\n",
    "valid_dataset_abstract = ShapeDataset(valid_abstract_persistence_images, valid_abstract_labels)\n",
    "test_dataset_abstract = ShapeDataset(test_abstract_persistence_images, test_abstract_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_laplacians = torch.utils.data.DataLoader(train_dataset_laplacians, batch_size=batch_size, shuffle=False)\n",
    "valid_loader_laplacians = torch.utils.data.DataLoader(valid_dataset_laplacians, batch_size=batch_size, shuffle=False)\n",
    "test_loader_laplacians = torch.utils.data.DataLoader(test_dataset_laplacians, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader_vr = torch.utils.data.DataLoader(train_dataset_vr, batch_size=batch_size, shuffle=False)\n",
    "valid_loader_vr = torch.utils.data.DataLoader(valid_dataset_vr, batch_size=batch_size, shuffle=False)\n",
    "test_loader_vr = torch.utils.data.DataLoader(test_dataset_vr, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader_abstract = torch.utils.data.DataLoader(train_dataset_abstract, batch_size=batch_size, shuffle=False)\n",
    "valid_loader_abstract = torch.utils.data.DataLoader(valid_dataset_abstract, batch_size=batch_size, shuffle=False)\n",
    "test_loader_abstract = torch.utils.data.DataLoader(test_dataset_abstract, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For single-input CNN (Laplacians)\n",
    "input_shape = train_data_gudhi_laplacians[0].shape\n",
    "num_classes = 2 # binary classification\n",
    "\n",
    "model_single_laplacians = CNN(input_shape, num_classes)\n",
    "\n",
    "# For dual-input CNNs (Laplacians + VR Persistence Images, Laplacians + Abstract Persistence Images)\n",
    "input_shape1 = train_data_gudhi_laplacians[0].shape\n",
    "input_shape2 = train_data_gudhi_vr_persistence_images[0].shape\n",
    "input_shape3 = train_data_gudhi_abstract_persistence_images[0].shape\n",
    "\n",
    "model_dual_lap_vr = DualInputCNN(input_shape1, input_shape2, num_classes)\n",
    "model_dual_lap_abstract = DualInputCNN(input_shape1, input_shape3, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_input(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader.dataset), accuracy\n",
    "\n",
    "\n",
    "def validate_single_input(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Validating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader.dataset), accuracy\n",
    "\n",
    "\n",
    "def train_dual_input(model, dataloader1, dataloader2, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    progress_bar = tqdm(zip(dataloader1, dataloader2), desc=\"Training (Dual Input)\", leave=False, total=min(len(dataloader1), len(dataloader2)))\n",
    "    \n",
    "    for (inputs1, labels1), (inputs2, labels2) in progress_bar:\n",
    "        inputs1, labels1 = inputs1.to(device), labels1.to(device)\n",
    "        inputs2, labels2 = inputs2.to(device), labels2.to(device)\n",
    "        \n",
    "        if not torch.equal(labels1, labels2):\n",
    "            print(\"Labels mismatch in dual-input training! Skipping batch.\")\n",
    "            continue\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        loss = criterion(outputs, labels1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels1).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    accuracy = correct / len(dataloader1.dataset)\n",
    "    return total_loss / len(dataloader1.dataset), accuracy\n",
    "\n",
    "\n",
    "def validate_dual_input(model, valid_loader_laplacians, valid_loader_vr, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (inputs1, _), (inputs2, targets) in zip(valid_loader_laplacians, valid_loader_vr):\n",
    "            inputs1, inputs2, targets = inputs1.to(device), inputs2.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs1, inputs2)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if outputs.shape[-1] > 1:\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            else:  # Binary classification\n",
    "                predicted = (outputs > 0.5).float()\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(valid_loader_laplacians)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_single_input(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(dataloader, desc=\"Testing\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Loss': [avg_loss],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1]\n",
    "    })\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    return metrics_df, cm\n",
    "\n",
    "\n",
    "def test_dual_input(model, dataloader1, dataloader2, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm(zip(dataloader1, dataloader2), desc=\"Testing (Dual Input)\", leave=False, total=min(len(dataloader1), len(dataloader2)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs1, _), (inputs2, targets) in progress_bar:\n",
    "            inputs1, inputs2, targets = inputs1.to(device), inputs2.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs1, inputs2)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if outputs.shape[-1] > 1:\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            else:  # Binary classification\n",
    "                predicted = (outputs > 0.5).float()\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader1.dataset)\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Loss': [avg_loss],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1]\n",
    "    })\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    return metrics_df, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualInputCNN(\n",
       "  (conv1_lap): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_lap): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool_lap): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (adaptive_pool_lap): AdaptiveAvgPool2d(output_size=(100, 100))\n",
       "  (conv1_pers): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_pers): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (adaptive_pool_pers): AdaptiveAvgPool2d(output_size=(100, 100))\n",
       "  (fc1): Linear(in_features=640000, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_single_laplacians.to(device)\n",
    "model_dual_lap_vr.to(device)\n",
    "model_dual_lap_abstract.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_single = optim.Adam(model_single_laplacians.parameters(), lr=0.001)\n",
    "optimizer_dual_vr = optim.Adam(model_dual_lap_vr.parameters(), lr=0.001)\n",
    "optimizer_dual_abstract = optim.Adam(model_dual_lap_abstract.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9aa9dd15ac432a83ae0df207f60c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103a1e5610a04167a9c6bb0f029b9f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdd2253f4d2449bb27c879cf33e2dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0717, Test Accuracy: 0.8327, Precision: 0.8710, Recall: 0.7770, F1 Score: 0.8213\n",
      "single-input model (Laplacians) Epoch 1/10, Train Loss: 0.1480, Train Acc: 0.6881, Valid Loss: 0.0515, Valid Acc: 0.8505\n",
      "single-input model (Laplacians)Training time: 284.96857619285583\n",
      "single-input model (Laplacians)Validation time: 10.811063051223755\n",
      "single-input model (Laplacians)Testing time: 11.447034120559692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d098535fa0e4ec9b1f8753f2a0f95d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba1a35b107b43988b341bbe8ecf3459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d947fd5089ed4f659626813572071487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0947, Test Accuracy: 0.8541, Precision: 0.9153, Recall: 0.7770, F1 Score: 0.8405\n",
      "single-input model (Laplacians) Epoch 2/10, Train Loss: 0.0093, Train Acc: 0.9131, Valid Loss: 0.0669, Valid Acc: 0.8612\n",
      "single-input model (Laplacians)Training time: 283.5330619812012\n",
      "single-input model (Laplacians)Validation time: 10.746689081192017\n",
      "single-input model (Laplacians)Testing time: 11.268712997436523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d9afd6a7f64a96b6ace38011074ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a19fe8af314554840b914c6b911b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94e743ef9344d2e8ea5f664c0c34b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0777, Test Accuracy: 0.8648, Precision: 0.9391, Recall: 0.7770, F1 Score: 0.8504\n",
      "single-input model (Laplacians) Epoch 3/10, Train Loss: 0.0086, Train Acc: 0.9237, Valid Loss: 0.0547, Valid Acc: 0.8826\n",
      "single-input model (Laplacians)Training time: 285.72096705436707\n",
      "single-input model (Laplacians)Validation time: 10.60057806968689\n",
      "single-input model (Laplacians)Testing time: 11.211443901062012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b57c2a0c514de2bca7460c7392ace0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd595f04aa14b87ba00b6f93da74421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b269a3a68d434088986ba929ef9c710b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0839, Test Accuracy: 0.8399, Precision: 0.8852, Recall: 0.7770, F1 Score: 0.8276\n",
      "single-input model (Laplacians) Epoch 4/10, Train Loss: 0.0078, Train Acc: 0.9337, Valid Loss: 0.0598, Valid Acc: 0.8577\n",
      "single-input model (Laplacians)Training time: 283.9581341743469\n",
      "single-input model (Laplacians)Validation time: 10.68253493309021\n",
      "single-input model (Laplacians)Testing time: 11.199007987976074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769630653b8b4d40a275a05daf2155e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6363c72d09064e15bf0a6c1a3cacc44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11615658455348fab2d5e7b1838fa829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0844, Test Accuracy: 0.8683, Precision: 0.9474, Recall: 0.7770, F1 Score: 0.8538\n",
      "single-input model (Laplacians) Epoch 5/10, Train Loss: 0.0079, Train Acc: 0.9313, Valid Loss: 0.0591, Valid Acc: 0.8790\n",
      "single-input model (Laplacians)Training time: 282.9487872123718\n",
      "single-input model (Laplacians)Validation time: 10.874052286148071\n",
      "single-input model (Laplacians)Testing time: 11.361538648605347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1770d817d14a3faa95a86e2d16ccdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2718491240a47848db2ace9c3819e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cb8278249c4440b6cd517129f0bc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0943, Test Accuracy: 0.8683, Precision: 0.9474, Recall: 0.7770, F1 Score: 0.8538\n",
      "single-input model (Laplacians) Epoch 6/10, Train Loss: 0.0073, Train Acc: 0.9350, Valid Loss: 0.0655, Valid Acc: 0.8861\n",
      "single-input model (Laplacians)Training time: 282.60761308670044\n",
      "single-input model (Laplacians)Validation time: 10.835114002227783\n",
      "single-input model (Laplacians)Testing time: 11.437210083007812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99d3c2bb1f94747a323cca10f8c34ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41453f79af9b489abbb81f39e8d7cda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014c6fc4e7814d2d9cdaf70fd5cf504e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0950, Test Accuracy: 0.8648, Precision: 0.9391, Recall: 0.7770, F1 Score: 0.8504\n",
      "single-input model (Laplacians) Epoch 7/10, Train Loss: 0.0069, Train Acc: 0.9369, Valid Loss: 0.0664, Valid Acc: 0.8754\n",
      "single-input model (Laplacians)Training time: 285.0575838088989\n",
      "single-input model (Laplacians)Validation time: 11.052955150604248\n",
      "single-input model (Laplacians)Testing time: 13.815110921859741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ae06f9a5ae40db8c078fc0126a5dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ac91afd2114b7486bd0018ced7b223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fc0ed1c0d6444cb4bd3c0410114094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1016, Test Accuracy: 0.8683, Precision: 0.9474, Recall: 0.7770, F1 Score: 0.8538\n",
      "single-input model (Laplacians) Epoch 8/10, Train Loss: 0.0066, Train Acc: 0.9394, Valid Loss: 0.0709, Valid Acc: 0.8826\n",
      "single-input model (Laplacians)Training time: 297.011314868927\n",
      "single-input model (Laplacians)Validation time: 10.82108187675476\n",
      "single-input model (Laplacians)Testing time: 11.438990116119385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6616c3145a84b92ab5e97b643db9652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caafb3f7cf714903b0abc7d2fd66c887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4122da020854355af1e6593c8fc30c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0928, Test Accuracy: 0.8648, Precision: 0.9391, Recall: 0.7770, F1 Score: 0.8504\n",
      "single-input model (Laplacians) Epoch 9/10, Train Loss: 0.0073, Train Acc: 0.9375, Valid Loss: 0.0655, Valid Acc: 0.8719\n",
      "single-input model (Laplacians)Training time: 282.84492111206055\n",
      "single-input model (Laplacians)Validation time: 10.492099046707153\n",
      "single-input model (Laplacians)Testing time: 10.816365003585815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58ae3d90ecd426b9e03e0b56609e42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d0d6d2dfe941bd90de1d45e11eb4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4178f5f83f400d854fe5aa89828d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0924, Test Accuracy: 0.8683, Precision: 0.9474, Recall: 0.7770, F1 Score: 0.8538\n",
      "single-input model (Laplacians) Epoch 10/10, Train Loss: 0.0071, Train Acc: 0.9337, Valid Loss: 0.0649, Valid Acc: 0.8790\n",
      "single-input model (Laplacians)Training time: 270.0683298110962\n",
      "single-input model (Laplacians)Validation time: 10.45020604133606\n",
      "single-input model (Laplacians)Testing time: 10.708115816116333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e47e0cedf074f79ba2cab7b0afe82e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fe679678f4460fbd9a1fe6e1f8e361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1775, Test Accuracy: 0.7900, Precision: 0.7083, Recall: 0.9784, F1 Score: 0.8218\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 1/10, Train Loss: 1.5072, Train Acc: 0.8500, Valid Loss: 6.4575, Valid Acc: 0.7544\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 300.40974497795105\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 12.838608026504517\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.95085597038269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc67af809784b50be10e3c773236c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7578611d78406382cab57b74c7a2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0505, Test Accuracy: 0.8256, Precision: 0.7616, Recall: 0.9424, F1 Score: 0.8424\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 2/10, Train Loss: 0.0230, Train Acc: 0.9394, Valid Loss: 1.3091, Valid Acc: 0.7936\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 310.8670151233673\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.757088899612427\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.946316003799438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90353e74183d4d11bd2df7eb855cbf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a7797b0a9e4eaa9ce39b7963740762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0297, Test Accuracy: 0.8007, Precision: 0.7293, Recall: 0.9496, F1 Score: 0.8250\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 3/10, Train Loss: 0.0059, Train Acc: 0.9531, Valid Loss: 0.7541, Valid Acc: 0.7580\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 294.63347697257996\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.19044804573059\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 11.516578912734985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ba94db14ef4528a683f04d9dae3057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26a7d6f6c9748278a2dce192b0f710c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0279, Test Accuracy: 0.8292, Precision: 0.7826, Recall: 0.9065, F1 Score: 0.8400\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 4/10, Train Loss: 0.0038, Train Acc: 0.9631, Valid Loss: 0.6337, Valid Acc: 0.7936\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 292.7700090408325\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.1696457862854\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 11.707612037658691\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19603e4f1d3d4217b32c1cc338dd4959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a800f3925df4995b9cf0924424773f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0267, Test Accuracy: 0.8363, Precision: 0.7925, Recall: 0.9065, F1 Score: 0.8456\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 5/10, Train Loss: 0.0030, Train Acc: 0.9781, Valid Loss: 0.6520, Valid Acc: 0.8043\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 294.84896302223206\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.197325229644775\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 11.795021057128906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc88e59615fb4cd1ae459ea64dce7981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d0aa0acf0944f7a810a40d53312212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0284, Test Accuracy: 0.8256, Precision: 0.7586, Recall: 0.9496, F1 Score: 0.8435\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 6/10, Train Loss: 0.0033, Train Acc: 0.9706, Valid Loss: 0.8697, Valid Acc: 0.7865\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 297.50654911994934\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.223896980285645\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.0153329372406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27cbc3414a44a06b1c8fec564f6c719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6b33ded3254f9cb79cea67c15a4a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0300, Test Accuracy: 0.8363, Precision: 0.7719, Recall: 0.9496, F1 Score: 0.8516\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 7/10, Train Loss: 0.0030, Train Acc: 0.9706, Valid Loss: 0.8935, Valid Acc: 0.8007\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 298.99859619140625\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.355785846710205\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.027915000915527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bb6f1192af4d27a724fa3be103c270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb53155ebb745089a667fc296c521df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0292, Test Accuracy: 0.8327, Precision: 0.7771, Recall: 0.9281, F1 Score: 0.8459\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 8/10, Train Loss: 0.0029, Train Acc: 0.9738, Valid Loss: 0.9355, Valid Acc: 0.8043\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 301.18250608444214\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.540793895721436\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.36794400215149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557ca6cbe6f0462595d72a9ab052370f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b83995f77b4e96a85ccee4e30f9993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0330, Test Accuracy: 0.8399, Precision: 0.7733, Recall: 0.9568, F1 Score: 0.8553\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 9/10, Train Loss: 0.0018, Train Acc: 0.9806, Valid Loss: 1.1475, Valid Acc: 0.8007\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 307.94442892074585\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.523165225982666\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.415775060653687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7603451cfa294536abf757b46459ee4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25983805d7d24d989c3469bc0d586c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0370, Test Accuracy: 0.8363, Precision: 0.7657, Recall: 0.9640, F1 Score: 0.8535\n",
      "dual-input model (Laplacians + VR Persistence Images) Epoch 10/10, Train Loss: 0.0023, Train Acc: 0.9819, Valid Loss: 1.3066, Valid Acc: 0.8114\n",
      "dual-input model (Laplacians + VR Persistence Images) Training time: 309.1259078979492\n",
      "dual-input model (Laplacians + VR Persistence Images) Validation time: 11.644209146499634\n",
      "dual-input model (Laplacians + VR Persistence Images) Testing time: 12.343419075012207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d93eb53f28455e8c9b431b1cd803d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb0c9bed1d849dba6a0e05bb53b64c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1020, Test Accuracy: 0.8363, Precision: 0.8908, Recall: 0.7626, F1 Score: 0.8217\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 1/10, Train Loss: 0.7053, Train Acc: 0.7650, Valid Loss: 2.1902, Valid Acc: 0.8790\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 305.16880106925964\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.53150224685669\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.365370035171509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4219252eab474cadec85afe158aa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e079d372644311ae7195789c439978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0747, Test Accuracy: 0.8434, Precision: 0.8992, Recall: 0.7698, F1 Score: 0.8295\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 2/10, Train Loss: 0.0058, Train Acc: 0.9206, Valid Loss: 1.6047, Valid Acc: 0.8790\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 303.85816287994385\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 12.206827163696289\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.337902069091797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d103f807208b40a1817c2b41796b0411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303aba1b20d443abac8612c6b330f94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0864, Test Accuracy: 0.8754, Precision: 0.9906, Recall: 0.7554, F1 Score: 0.8571\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 3/10, Train Loss: 0.0047, Train Acc: 0.9481, Valid Loss: 1.8542, Valid Acc: 0.9075\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 306.1938419342041\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.94249415397644\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.472815036773682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb90bd09bed2404c86231c481cda2a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16af068c2cf47efa02e7264f155a383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0826, Test Accuracy: 0.8683, Precision: 0.9722, Recall: 0.7554, F1 Score: 0.8502\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 4/10, Train Loss: 0.0042, Train Acc: 0.9619, Valid Loss: 1.7803, Valid Acc: 0.9075\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 301.17805194854736\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.46026611328125\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.230353832244873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a207985dcbc243048085a3bcc1810b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde1d20a99474267b17d47a6f3221131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0950, Test Accuracy: 0.8719, Precision: 0.9813, Recall: 0.7554, F1 Score: 0.8537\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 5/10, Train Loss: 0.0035, Train Acc: 0.9650, Valid Loss: 2.0379, Valid Acc: 0.8932\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 300.5430369377136\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.433439016342163\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.322306871414185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174dcb88549342e2b1119ebde2ebfef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddf8645e05445e38df562d9ba311621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0663, Test Accuracy: 0.8754, Precision: 0.9815, Recall: 0.7626, F1 Score: 0.8583\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 6/10, Train Loss: 0.0032, Train Acc: 0.9681, Valid Loss: 1.4257, Valid Acc: 0.9075\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 301.1070120334625\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.485507726669312\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.305685997009277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1acc4d604024d50abcfd69a65e3c61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20e7f995271412baa947685947402a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0880, Test Accuracy: 0.8719, Precision: 0.9725, Recall: 0.7626, F1 Score: 0.8548\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 7/10, Train Loss: 0.0029, Train Acc: 0.9694, Valid Loss: 1.8792, Valid Acc: 0.9110\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 301.0001528263092\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.406236171722412\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.309349298477173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43affaad23b49eb98b03ed34bca0cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244043f2374f49ae95d62c6ac579d0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0673, Test Accuracy: 0.8719, Precision: 0.9640, Recall: 0.7698, F1 Score: 0.8560\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 8/10, Train Loss: 0.0031, Train Acc: 0.9694, Valid Loss: 1.4651, Valid Acc: 0.9004\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 299.80732703208923\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.48462200164795\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.198882818222046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955d1c9060ad46dd81c7030148d950c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3d8d9c55184db2856e5411d6359882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0876, Test Accuracy: 0.8790, Precision: 0.9730, Recall: 0.7770, F1 Score: 0.8640\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 9/10, Train Loss: 0.0032, Train Acc: 0.9681, Valid Loss: 1.9126, Valid Acc: 0.9039\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 296.18436670303345\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.312620162963867\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 11.981914043426514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1953b07f7a4948a0eba60d33acc84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Dual Input):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794fb6c45cd246f1a2a7b0ac61237fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing (Dual Input):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0802, Test Accuracy: 0.8826, Precision: 0.9907, Recall: 0.7698, F1 Score: 0.8664\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Epoch 10/10, Train Loss: 0.0025, Train Acc: 0.9769, Valid Loss: 1.7323, Valid Acc: 0.9039\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Training time: 297.94743299484253\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Validation time: 11.351524829864502\n",
      "dual-input model (Laplacians + Abstract Persistence Images) Testing time: 12.191735982894897\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store all metrics for each epoch\n",
    "test_metrics_single_list = []\n",
    "test_metrics_dual_vr_list = []\n",
    "test_metrics_dual_abstract_list = []\n",
    "\n",
    "# Initialize empty lists to store all confusion matrices for each epoch\n",
    "cm_single_list = []\n",
    "cm_dual_vr_list = []\n",
    "cm_dual_abstract_list = []\n",
    "\n",
    "# Training loop for single-input model (Laplacians)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "      train_time_start = time.time()\n",
    "      model_single_laplacians.train()  # Ensure the model is in training mode\n",
    "\n",
    "      train_loss, train_acc = train_single_input(model_single_laplacians, train_loader_laplacians, optimizer_single, criterion, device)\n",
    "\n",
    "      train_time_end = time.time()\n",
    "\n",
    "      valid_time_start = time.time()\n",
    "\n",
    "      model_single_laplacians.eval()  # Switch model to evaluation mode after training\n",
    "\n",
    "\n",
    "\n",
    "      valid_loss, valid_acc = validate_single_input(model_single_laplacians, valid_loader_laplacians, criterion, device)\n",
    "\n",
    "      valid_time_end = time.time()\n",
    "\n",
    "      # Test the model after each epoch\n",
    "\n",
    "      test_time_start = time.time()\n",
    "      test_metrics_single, cm_single = test_single_input(model_single_laplacians, test_loader_laplacians, criterion, device)\n",
    "      test_time_end = time.time()\n",
    "\n",
    "      # Combine train, valid, and test metrics for this epoch\n",
    "      metrics = test_metrics_single.copy()\n",
    "      metrics['Train Loss'] = train_loss\n",
    "      metrics['Train Accuracy'] = train_acc\n",
    "      metrics['Valid Loss'] = valid_loss\n",
    "      metrics['Valid Accuracy'] = valid_acc\n",
    "\n",
    "      # Append to the list\n",
    "      test_metrics_single_list.append(metrics)\n",
    "      cm_single_list.append(cm_single)\n",
    "\n",
    "      print(f\"single-input model (Laplacians) Epoch {epoch+1}/{num_epochs}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "            f\"Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "      torch.save(model_single_laplacians.state_dict(), \"Trained CNNs/model_single_h0_lap_unif_nonunif_gudhi_medical_epoch_{}.pth\".format(epoch+1))\n",
    "\n",
    "      print(f\"single-input model (Laplacians)Training time: {train_time_end - train_time_start}\")\n",
    "      print(f\"single-input model (Laplacians)Validation time: {valid_time_end - valid_time_start}\")\n",
    "      print(f\"single-input model (Laplacians)Testing time: {test_time_end - test_time_start}\")\n",
    "\n",
    "\n",
    "# Training loop for dual-input model (Laplacians + VR Persistence Images)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "      train_time_start = time.time()\n",
    "      model_dual_lap_vr.train()  # Ensure the model is in training mode\n",
    "      train_loss, train_acc = train_dual_input(model_dual_lap_vr, train_loader_laplacians, train_loader_vr, optimizer_dual_vr, criterion, device)\n",
    "      train_time_end = time.time()\n",
    "      valid_time_start = time.time()\n",
    "      model_dual_lap_vr.eval()  # Switch model to evaluation mode after training\n",
    "\n",
    "\n",
    "      valid_loss, valid_acc = validate_dual_input(model_dual_lap_vr, valid_loader_laplacians, valid_loader_vr, criterion, device)\n",
    "      valid_time_end = time.time()\n",
    "\n",
    "      # Test the model after each epoch\n",
    "      test_time_start = time.time()\n",
    "      test_metrics_dual_vr, cm_dual_vr = test_dual_input(model_dual_lap_vr, test_loader_laplacians, test_loader_vr, criterion, device)\n",
    "      test_time_end = time.time()\n",
    "\n",
    "      # Combine train, valid, and test metrics for this epoch\n",
    "      metrics = test_metrics_dual_vr.copy()\n",
    "      metrics['Train Loss'] = train_loss\n",
    "      metrics['Train Accuracy'] = train_acc\n",
    "      metrics['Valid Loss'] = valid_loss\n",
    "      metrics['Valid Accuracy'] = valid_acc\n",
    "\n",
    "      # Append to the list\n",
    "      test_metrics_dual_vr_list.append(metrics)\n",
    "      cm_dual_vr_list.append(cm_dual_vr)\n",
    "\n",
    "      print(f\"dual-input model (Laplacians + VR Persistence Images) Epoch {epoch+1}/{num_epochs}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "            f\"Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "      torch.save(model_dual_lap_vr.state_dict(), \"Trained CNNs/model_dual_h0_lap_vr_unif_nonunif_gudhi_medical_epoch_{}.pth\".format(epoch+1))\n",
    "\n",
    "      print(f\"dual-input model (Laplacians + VR Persistence Images) Training time: {train_time_end - train_time_start}\")\n",
    "      print(f\"dual-input model (Laplacians + VR Persistence Images) Validation time: {valid_time_end - valid_time_start}\")\n",
    "      print(f\"dual-input model (Laplacians + VR Persistence Images) Testing time: {test_time_end - test_time_start}\")\n",
    "\n",
    "\n",
    "# Training loop for dual-input model (Laplacians + Abstract Persistence Images)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "      train_time_start = time.time()\n",
    "      model_dual_lap_abstract.train()  # Ensure the model is in training mode\n",
    "      train_loss, train_acc = train_dual_input(model_dual_lap_abstract, train_loader_laplacians, train_loader_abstract, optimizer_dual_abstract, criterion, device)\n",
    "      train_time_end = time.time()\n",
    "\n",
    "      valid_time_start = time.time()\n",
    "      model_dual_lap_abstract.eval()  # Switch model to evaluation mode after training\n",
    "      valid_loss, valid_acc = validate_dual_input(model_dual_lap_abstract, valid_loader_laplacians, valid_loader_abstract, criterion, device)\n",
    "      valid_time_end = time.time()\n",
    "\n",
    "      # Test the model after each epoch\n",
    "      test_time_start = time.time()\n",
    "      test_metrics_dual_abstract, cm_dual_abstract = test_dual_input(model_dual_lap_abstract, test_loader_laplacians, test_loader_abstract, criterion, device)\n",
    "      test_time_end = time.time()\n",
    "\n",
    "      # Combine train, valid, and test metrics for this epoch\n",
    "      metrics = test_metrics_dual_abstract.copy()\n",
    "      metrics['Train Loss'] = train_loss\n",
    "      metrics['Train Accuracy'] = train_acc\n",
    "      metrics['Valid Loss'] = valid_loss\n",
    "      metrics['Valid Accuracy'] = valid_acc\n",
    "\n",
    "      # Append to the list\n",
    "      test_metrics_dual_abstract_list.append(metrics)\n",
    "      cm_dual_abstract_list.append(cm_dual_abstract)\n",
    "\n",
    "      print(f\"dual-input model (Laplacians + Abstract Persistence Images) Epoch {epoch+1}/{num_epochs}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "            f\"Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "      torch.save(model_dual_lap_abstract.state_dict(), \"Trained CNNs/model_dual_h0_lap_abstract_unif_nonunif_gudhi_medical_epoch_{}.pth\".format(epoch+1))\n",
    "\n",
    "      print(f\"dual-input model (Laplacians + Abstract Persistence Images) Training time: {train_time_end - train_time_start}\")\n",
    "      print(f\"dual-input model (Laplacians + Abstract Persistence Images) Validation time: {valid_time_end - valid_time_start}\")\n",
    "      print(f\"dual-input model (Laplacians + Abstract Persistence Images) Testing time: {test_time_end - test_time_start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single-input model (Laplacians) Test Metrics:\n",
      "       Test Loss  Test Accuracy  Precision    Recall  F1 Score  Train Loss  \\\n",
      "Epoch                                                                        \n",
      "1       0.071685       0.832740   0.870968  0.776978  0.821293    0.147951   \n",
      "2       0.094749       0.854093   0.915254  0.776978  0.840467    0.009275   \n",
      "3       0.077691       0.864769   0.939130  0.776978  0.850394    0.008620   \n",
      "4       0.083901       0.839858   0.885246  0.776978  0.827586    0.007813   \n",
      "5       0.084364       0.868327   0.947368  0.776978  0.853755    0.007856   \n",
      "6       0.094266       0.868327   0.947368  0.776978  0.853755    0.007256   \n",
      "7       0.094979       0.864769   0.939130  0.776978  0.850394    0.006870   \n",
      "8       0.101566       0.868327   0.947368  0.776978  0.853755    0.006622   \n",
      "9       0.092840       0.864769   0.939130  0.776978  0.850394    0.007278   \n",
      "10      0.092403       0.868327   0.947368  0.776978  0.853755    0.007144   \n",
      "\n",
      "       Train Accuracy  Valid Loss  Valid Accuracy  \n",
      "Epoch                                              \n",
      "1            0.688125    0.051491        0.850534  \n",
      "2            0.913125    0.066858        0.861210  \n",
      "3            0.923750    0.054732        0.882562  \n",
      "4            0.933750    0.059821        0.857651  \n",
      "5            0.931250    0.059141        0.879004  \n",
      "6            0.935000    0.065468        0.886121  \n",
      "7            0.936875    0.066440        0.875445  \n",
      "8            0.939375    0.070898        0.882562  \n",
      "9            0.937500    0.065507        0.871886  \n",
      "10           0.933750    0.064928        0.879004  \n",
      "\n",
      "Dual-input model (Laplacians + VR Persistence Images) Test Metrics:\n",
      "       Test Loss  Test Accuracy  Precision    Recall  F1 Score  Train Loss  \\\n",
      "Epoch                                                                        \n",
      "1       0.177495       0.790036   0.708333  0.978417  0.821752    1.507173   \n",
      "2       0.050500       0.825623   0.761628  0.942446  0.842444    0.023034   \n",
      "3       0.029733       0.800712   0.729282  0.949640  0.825000    0.005933   \n",
      "4       0.027928       0.829181   0.782609  0.906475  0.840000    0.003832   \n",
      "5       0.026743       0.836299   0.792453  0.906475  0.845638    0.002989   \n",
      "6       0.028411       0.825623   0.758621  0.949640  0.843450    0.003267   \n",
      "7       0.030050       0.836299   0.771930  0.949640  0.851613    0.003047   \n",
      "8       0.029174       0.832740   0.777108  0.928058  0.845902    0.002892   \n",
      "9       0.032995       0.839858   0.773256  0.956835  0.855305    0.001793   \n",
      "10      0.036958       0.836299   0.765714  0.964029  0.853503    0.002346   \n",
      "\n",
      "       Train Accuracy  Valid Loss  Valid Accuracy  \n",
      "Epoch                                              \n",
      "1            0.850000    6.457512        0.754448  \n",
      "2            0.939375    1.309109        0.793594  \n",
      "3            0.953125    0.754138        0.758007  \n",
      "4            0.963125    0.633678        0.793594  \n",
      "5            0.978125    0.652043        0.804270  \n",
      "6            0.970625    0.869733        0.786477  \n",
      "7            0.970625    0.893537        0.800712  \n",
      "8            0.973750    0.935543        0.804270  \n",
      "9            0.980625    1.147488        0.800712  \n",
      "10           0.981875    1.306646        0.811388  \n",
      "\n",
      "Dual-input model (Laplacians + Abstract Persistence Images) Test Metrics:\n",
      "       Test Loss  Test Accuracy  Precision    Recall  F1 Score  Train Loss  \\\n",
      "Epoch                                                                        \n",
      "1       0.102009       0.836299   0.890756  0.762590  0.821705    0.705339   \n",
      "2       0.074656       0.843416   0.899160  0.769784  0.829457    0.005813   \n",
      "3       0.086439       0.875445   0.990566  0.755396  0.857143    0.004652   \n",
      "4       0.082552       0.868327   0.972222  0.755396  0.850202    0.004181   \n",
      "5       0.095022       0.871886   0.981308  0.755396  0.853659    0.003455   \n",
      "6       0.066251       0.875445   0.981481  0.762590  0.858300    0.003232   \n",
      "7       0.087998       0.871886   0.972477  0.762590  0.854839    0.002949   \n",
      "8       0.067281       0.871886   0.963964  0.769784  0.856000    0.003135   \n",
      "9       0.087647       0.879004   0.972973  0.776978  0.864000    0.003156   \n",
      "10      0.080179       0.882562   0.990741  0.769784  0.866397    0.002533   \n",
      "\n",
      "       Train Accuracy  Valid Loss  Valid Accuracy  \n",
      "Epoch                                              \n",
      "1            0.765000    2.190236        0.879004  \n",
      "2            0.920625    1.604672        0.879004  \n",
      "3            0.948125    1.854177        0.907473  \n",
      "4            0.961875    1.780332        0.907473  \n",
      "5            0.965000    2.037894        0.893238  \n",
      "6            0.968125    1.425666        0.907473  \n",
      "7            0.969375    1.879175        0.911032  \n",
      "8            0.969375    1.465114        0.900356  \n",
      "9            0.968125    1.912579        0.903915  \n",
      "10           0.976875    1.732273        0.903915  \n"
     ]
    }
   ],
   "source": [
    "# Convert the lists of metrics into DataFrames with epoch as the index\n",
    "test_metrics_single_df = pd.concat(test_metrics_single_list, ignore_index=True)\n",
    "test_metrics_dual_vr_df = pd.concat(test_metrics_dual_vr_list, ignore_index=True)\n",
    "test_metrics_dual_abstract_df = pd.concat(test_metrics_dual_abstract_list, ignore_index=True)\n",
    "\n",
    "# Add 'Epoch' as new column\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "\n",
    "test_metrics_single_df['Epoch'] = epochs\n",
    "test_metrics_dual_vr_df['Epoch'] = epochs\n",
    "test_metrics_dual_abstract_df['Epoch'] = epochs\n",
    "\n",
    "# Set 'Epoch' as index\n",
    "test_metrics_single_df.set_index('Epoch', inplace=True)\n",
    "test_metrics_dual_vr_df.set_index('Epoch', inplace=True)\n",
    "test_metrics_dual_abstract_df.set_index('Epoch', inplace=True)\n",
    "\n",
    "# Rename first two columns to 'Test Loss' and 'Test Accuracy'\n",
    "test_metrics_single_df.rename(columns={'Loss': 'Test Loss', 'Accuracy': 'Test Accuracy'}, inplace=True)\n",
    "test_metrics_dual_vr_df.rename(columns={'Loss': 'Test Loss', 'Accuracy': 'Test Accuracy'}, inplace=True)\n",
    "test_metrics_dual_abstract_df.rename(columns={'Loss': 'Test Loss', 'Accuracy': 'Test Accuracy'}, inplace=True)\n",
    "\n",
    "# Print final test metrics for all models\n",
    "print(\"\\nSingle-input model (Laplacians) Test Metrics:\")\n",
    "print(test_metrics_single_df)\n",
    "\n",
    "print(\"\\nDual-input model (Laplacians + VR Persistence Images) Test Metrics:\")\n",
    "print(test_metrics_dual_vr_df)\n",
    "\n",
    "print(\"\\nDual-input model (Laplacians + Abstract Persistence Images) Test Metrics:\")\n",
    "print(test_metrics_dual_abstract_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test metrics to CSV files\n",
    "\n",
    "test_metrics_single_df.to_csv('test_metrics_single_h0_lap_unif_nonunif_gudhi_medical.csv')\n",
    "test_metrics_dual_vr_df.to_csv('test_metrics_dual_h0_lap_vr_unif_nonunif_gudhi_medical.csv')\n",
    "test_metrics_dual_abstract_df.to_csv('test_metrics_dual_h0_lap_abstract_unif_nonunif_gudhi_medical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and export confusion matrices to \"Confusion\\ Matrices/\" folder\n",
    "\n",
    "# Single-input model (Laplacians)\n",
    "for i, cm in enumerate(cm_single_list):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 14})\n",
    "    plt.title(f\"Confusion Matrix - Single-input Model (Laplacians), Epoch {i+1}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"Confusion Matrices/single_h0_lap_unif_nonunif_gudhi_medical_cm_epoch_{i+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Dual-input model (Laplacians + VR Persistence Images)\n",
    "for i, cm in enumerate(cm_dual_vr_list):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 14})\n",
    "    plt.title(f\"Confusion Matrix - Dual-input Model (Laplacians + VR Persistence Images), Epoch {i+1}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"Confusion Matrices/dual_h0_lap_vr_unif_nonunif_gudhi_medical_cm_epoch_{i+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Dual-input model (Laplacians + Abstract Persistence Images)\n",
    "for i, cm in enumerate(cm_dual_abstract_list):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={'size': 14})\n",
    "    plt.title(f\"Confusion Matrix - Dual-input Model (Laplacians + Abstract Persistence Images), Epoch {i+1}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f\"Confusion Matrices/dual_h0_lap_abstract_unif_nonunif_gudhi_medical_cm_epoch_{i+1}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FiltrationsForGNNsLargeData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
