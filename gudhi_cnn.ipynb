{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# import Gudhi Shape Dataset files\n",
    "points = []\n",
    "laplacians = []\n",
    "vr_persistence_images = []\n",
    "abstract_persistence_images = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    points.append(np.genfromtxt('Gudhi Shape Dataset/shape_'+str(i)+'_points.csv', delimiter=',', skip_header=0))\n",
    "    laplacians.append(np.genfromtxt('Gudhi Shape Dataset/shape_'+str(i)+'_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    vr_persistence_images.append(np.genfromtxt('Gudhi Shape Dataset/shape_'+str(i)+'_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    abstract_persistence_images.append(np.genfromtxt('Gudhi Shape Dataset/shape_'+str(i)+'_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "\n",
    "\n",
    "# import labels for the shapes\n",
    "shape_labels = np.genfromtxt('Gudhi Shape Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "shape_labels = shape_labels.astype(int)[:,2]\n",
    "print(shape_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)  # Conv layer 1\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  # Conv layer 2\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
    "        self.fc1 = nn.Linear(32 * input_shape[0] * input_shape[1], 128)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(128, num_classes)  # Fully connected layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten for FC layers\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = F.relu(self.fc1(x))  # FC layer with ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return F.log_softmax(x, dim=1)  # Log-Softmax for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_for_data_type(data_type, data, labels, input_shape):\n",
    "    # Create dataset and split into train/test sets\n",
    "    dataset = ShapeDataset(data, labels)\n",
    "    train_data, test_data = train_test_split(dataset.data, test_size=0.2, random_state=42)\n",
    "    train_labels, test_labels = train_test_split(dataset.labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert to custom Dataset format for train and test sets\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.stack(train_data), torch.tensor(train_labels))\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.stack(test_data), torch.tensor(test_labels))\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Define model\n",
    "    model = CNN(input_shape=input_shape, num_classes=2).to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for multi-class classification\n",
    "\n",
    "    epoch_results = []\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Training model for {data_type} - Epoch {epoch}/{num_epochs}\")\n",
    "        train_loss = train(model, device, train_dataloader, optimizer, criterion, epoch)\n",
    "        test_loss, accuracy = test(model, device, test_dataloader, criterion)\n",
    "        \n",
    "        # Store results\n",
    "        epoch_results.append({\n",
    "            'Epoch': epoch,\n",
    "            'Train Loss': train_loss,\n",
    "            'Test Loss': test_loss,\n",
    "            'Test Accuracy (%)': accuracy\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    print(f\"\\nTraining and testing results for {data_type}:\")\n",
    "    print(epoch_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        tk0.set_postfix(loss=loss.item())\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d3/99lvl9fd1673ngz9966pvq100000gn/T/ipykernel_3616/4276303316.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = torch.utils.data.TensorDataset(torch.stack(train_data), torch.tensor(train_labels))\n",
      "/var/folders/d3/99lvl9fd1673ngz9966pvq100000gn/T/ipykernel_3616/4276303316.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_dataset = torch.utils.data.TensorDataset(torch.stack(test_data), torch.tensor(test_labels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16c3e932f7a4a778d491c4ae72be048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and test for Laplacians (1000x1000 input)\n",
    "train_and_test_for_data_type(\"Laplacians\", laplacians, shape_labels, input_shape=(1000, 1000))\n",
    "\n",
    "# Train and test for VR Persistence Images (100x100 input)\n",
    "train_and_test_for_data_type(\"VR Persistence Images\", vr_persistence_images, shape_labels, input_shape=(100, 100))\n",
    "\n",
    "# Train and test for Abstract Persistence Images (100x100 input)\n",
    "train_and_test_for_data_type(\"Abstract Persistence Images\", abstract_persistence_images, shape_labels, input_shape=(100, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FiltrationsForGNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
