{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import labels for the shapes\n",
    "shape_labels = np.genfromtxt('../FiltrationsForGNNs/Gudhi Shape Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "shape_labels = shape_labels.astype(int)[:,2]\n",
    "print(shape_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 200 samples.\n",
      "Shape of laplacians: (200, 1000, 1000)\n",
      "Shape of VR persistence images: (200, 100, 100)\n",
      "Shape of abstract persistence images: (200, 100, 100)\n",
      "Shape of selected labels: (200,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 200 # currently set to full dataset\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(len(shape_labels), size=num_samples, replace=False)\n",
    "base = '../FiltrationsForGNNs/Gudhi Shape Dataset/'\n",
    "# Select the corresponding data and labels\n",
    "laplacians = []\n",
    "vr_persistence_images = []\n",
    "abstract_persistence_images = []\n",
    "selected_labels = []\n",
    "\n",
    "for i in random_indices:\n",
    "    laplacians.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    vr_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    abstract_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    selected_labels.append(shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "selected_labels = np.array(selected_labels)\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(laplacians).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(vr_persistence_images).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(abstract_persistence_images).shape}\")\n",
    "print(f\"Shape of selected labels: {selected_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Adaptive Pooling to resize to 100x100\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((100, 100))\n",
    "        \n",
    "        # Dynamically calculate input size to fc1\n",
    "        self.feature_size = self._get_feature_size(input_shape)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.feature_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_feature_size(self, input_shape):\n",
    "        # Create a dummy input to calculate size after conv and pooling\n",
    "        dummy_input = torch.zeros(1, 1, *input_shape)\n",
    "        x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to get 100x100 size\n",
    "        x = self.adaptive_pool(x)\n",
    "        return x.numel()  # Number of elements after flattening\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Apply adaptive pooling to resize to 100x100\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualInputCNN(nn.Module):\n",
    "    def __init__(self, input_shape1, input_shape2, num_classes=2):\n",
    "        super(DualInputCNN, self).__init__()\n",
    "\n",
    "        # Laplacian input path with additional pooling to reduce to 100x100\n",
    "        self.conv1_lap = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_lap = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_lap = nn.MaxPool2d(2, 2)  # Reduce spatial dimensions\n",
    "        self.adaptive_pool_lap = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Persistence image input path (no pooling)\n",
    "        self.conv1_pers = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_pers = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.adaptive_pool_pers = nn.AdaptiveAvgPool2d((100, 100))  # Resize to 100x100\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 100 * 100 + 32 * 100 * 100, 128)  # Adjusted for 100x100 input\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Laplacians path (downsampling to 100x100)\n",
    "        x1 = F.relu(self.conv1_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # First pool: 250x250 -> 125x125\n",
    "        x1 = F.relu(self.conv2_lap(x1))\n",
    "        x1 = self.pool_lap(x1)  # Second pool: 125x125 -> 62x62\n",
    "        x1 = self.adaptive_pool_lap(x1)  # Resize to 100x100\n",
    "        \n",
    "        # Persistence images path (no pooling)\n",
    "        x2 = F.relu(self.conv1_pers(x2))\n",
    "        x2 = F.relu(self.conv2_pers(x2))\n",
    "        x2 = self.adaptive_pool_pers(x2)  # Ensure persistence images are 100x100\n",
    "        \n",
    "        # Concatenate along dim=1 (channels)\n",
    "        x = torch.cat((x1, x2), dim=1)  # Concatenates the outputs along the channel axis\n",
    "\n",
    "        # Flatten for fully connected layer\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_input(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with single input\n",
    "        output = model(data)  # Forward through the single-input model\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        tk0.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def test_single_input(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)  # Forward through the single-input model\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_single_input(data_type, data, labels, input_shape):\n",
    "    # Create dataset and split into train/test sets\n",
    "    dataset = ShapeDataset(data, labels)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        dataset.data, dataset.labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert to custom Dataset format for train and test sets\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.stack(train_data), train_labels)\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.stack(test_data), test_labels)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Define CNN model with input_shape\n",
    "    model = CNN(input_shape=input_shape, num_classes=len(set(labels))).to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "\n",
    "    epoch_results = []\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Training model for {data_type} - Epoch {epoch}/{num_epochs}\")\n",
    "        train_loss, accuracy = train_single_input(model, device, train_dataloader, optimizer, criterion, epoch)\n",
    "        test_loss, accuracy, precision, recall, f1 = test_single_input(model, device, test_dataloader, criterion)\n",
    "\n",
    "        # Store results\n",
    "        epoch_results.append({\n",
    "            'Epoch': epoch,\n",
    "            'Test Loss': test_loss,\n",
    "            'Test Accuracy (%)': accuracy,\n",
    "            'Test Precision (%)': precision * 100,\n",
    "            'Test Recall (%)': recall * 100,\n",
    "            'Test F1 Score': f1\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    print(f\"\\nTesting results for {data_type}:\")\n",
    "    print(epoch_results_df)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_dual_input(data_type, data1, data2, labels, input_shape1, input_shape2):\n",
    "    dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data1]  # Shape [1, 100, 100]\n",
    "    dataset2 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data2]  # Shape [1, 100, 100]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    train_data1, test_data1, train_data2, test_data2, train_labels, test_labels = train_test_split(\n",
    "        dataset1, dataset2, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(train_data1), torch.stack(train_data2), train_labels\n",
    "    )\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(test_data1), torch.stack(test_data2), test_labels\n",
    "    )\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = DualInputCNN(input_shape1=input_shape1, input_shape2=input_shape2, num_classes=len(set(labels))).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_results = []\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Training model for {data_type} - Epoch {epoch}/5\")\n",
    "        \n",
    "        # Training step\n",
    "        train_loss, train_accuracy = train_dual_input(model, device, train_dataloader, optimizer, criterion, epoch)\n",
    "        \n",
    "        # Testing step\n",
    "        test_loss, test_accuracy, precision, recall, f1 = test_dual_input(model, device, test_dataloader, criterion)\n",
    "        \n",
    "        # Storing results\n",
    "        epoch_results.append({\n",
    "            'Epoch': epoch,\n",
    "            'Test Loss': test_loss,\n",
    "            'Test Accuracy (%)': test_accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    print(f\"\\nTesting results for {data_type}:\")\n",
    "    print(epoch_results_df)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dual_input(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "    for batch_idx, (data1, data2, target) in enumerate(tk0):\n",
    "        data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with dual input\n",
    "        output = model(data1, data2)  # Forward through the dual-input model\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        tk0.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def test_dual_input(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data1, data2, target in test_loader:\n",
    "            data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "            output = model(data1, data2)  # Forward through the dual-input model\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            # Collect all labels and predictions for additional metrics\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Return test loss, accuracy, and additional metrics\n",
    "    return avg_loss, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a957c4381324aba94cb04c9a05afa69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4897725ca1be468aaf99f85f860312cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b202c7291bb49fca21e6917a15f54aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4e45b6c3d448c683a63c115d228c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907da05b28344a97b0dc1f2319c179c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fed753c2ea4c62952394c606bfbf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476106ae044c422e9820ad19f24f54e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450850e9157a445687927535bb253bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789d198f1a57426db26b5109079cb7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians - Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1151478488e4f768f09d3a6c3005fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing results for Laplacians:\n",
      "   Epoch  Test Loss  Test Accuracy (%)  Test Precision (%)  Test Recall (%)  \\\n",
      "0      1   5.966245               70.0           80.588235             70.0   \n",
      "1      2   0.562329               45.0           20.250000             45.0   \n",
      "2      3   0.198150               92.5           93.400000             92.5   \n",
      "3      4   0.191942               95.0           95.416667             95.0   \n",
      "4      5   0.154823               95.0           95.416667             95.0   \n",
      "5      6   0.194205               95.0           95.416667             95.0   \n",
      "6      7   0.131854               95.0           95.416667             95.0   \n",
      "7      8   0.169439               95.0           95.416667             95.0   \n",
      "8      9   0.139449               95.0           95.416667             95.0   \n",
      "9     10   0.115736               95.0           95.416667             95.0   \n",
      "\n",
      "   Test F1 Score  \n",
      "0       0.657143  \n",
      "1       0.279310  \n",
      "2       0.923985  \n",
      "3       0.949616  \n",
      "4       0.949616  \n",
      "5       0.949616  \n",
      "6       0.949616  \n",
      "7       0.949616  \n",
      "8       0.949616  \n",
      "9       0.949616  \n"
     ]
    }
   ],
   "source": [
    "# Train and test for Laplacians (1000x1000 input)\n",
    "lap = train_and_test_single_input(\"Laplacians\", laplacians, selected_labels, input_shape=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19af620b0d304708ae936f1a753df610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2e542682d146eb84878abc6c2f0351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0fc4bf557949f4a1ef666ec5589c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf3a8eb3c59405e8c3ed2feb9d48164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0569bffa254038a2679ec121e41595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 6/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37dc75df4514a2a8ef1668d6960721c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 7/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53bedc3f796425095ccbddcda9c463e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 8/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e9d113cee9466a937c5926f5b1f9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 9/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1626b7587b45edade7bd7112f00590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + VR Persistence Images - Epoch 10/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82c88b992954410817931277cb4449e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing results for Laplacians + VR Persistence Images:\n",
      "   Epoch  Test Loss  Test Accuracy (%)  Precision  Recall  F1 Score\n",
      "0      1  36.266187               85.0   0.862088   0.850  0.846875\n",
      "1      2   3.339916               62.5   0.795455   0.625  0.583164\n",
      "2      3   0.427565               92.5   0.935714   0.925  0.925141\n",
      "3      4   1.042344               92.5   0.935714   0.925  0.925141\n",
      "4      5   0.252098               87.5   0.898148   0.875  0.871297\n",
      "5      6   0.848984               92.5   0.935714   0.925  0.925141\n",
      "6      7   0.003119              100.0   1.000000   1.000  1.000000\n",
      "7      8   0.148613               95.0   0.955000   0.950  0.950125\n",
      "8      9   0.001413              100.0   1.000000   1.000  1.000000\n",
      "9     10   0.002278              100.0   1.000000   1.000  1.000000\n"
     ]
    }
   ],
   "source": [
    "dual_vr = train_and_test_dual_input(\"Laplacians + VR Persistence Images\", laplacians, vr_persistence_images, selected_labels, (1000, 1000), (100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bd829cc0314335984d593d6be7d6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88531339354e45e7a4d27870488de332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2e403a2a5a42daa67f797877ec94c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a522fdd9333f4e58aa3e5c187e408778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2b094a16bf4557bc1d39f1232e5ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 6/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfa180b344f4834a2954cd4f1746de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 7/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec082426194af0b7052e0c9b6e4e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 8/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1466a3764c844c0f8efb0d91aec95ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 9/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56eec8104d83408fa6a8ca86e21629a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Laplacians + Abstract Persistence Images - Epoch 10/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db4f4bdd75e4192bb58a7744d44e821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing results for Laplacians + Abstract Persistence Images:\n",
      "   Epoch  Test Loss  Test Accuracy (%)  Precision  Recall  F1 Score\n",
      "0      1   2.930052               82.5   0.826692   0.825  0.825330\n",
      "1      2   0.542180               87.5   0.885338   0.875  0.875235\n",
      "2      3   0.334232               92.5   0.926441   0.925  0.925141\n",
      "3      4   0.189809               95.0   0.955000   0.950  0.950125\n",
      "4      5   0.009176              100.0   1.000000   1.000  1.000000\n",
      "5      6   0.013109               97.5   0.976316   0.975  0.975047\n",
      "6      7   0.049952               97.5   0.976316   0.975  0.975047\n",
      "7      8   0.270962               92.5   0.934000   0.925  0.923985\n",
      "8      9   0.055290               97.5   0.976087   0.975  0.974921\n",
      "9     10   0.060581               97.5   0.976316   0.975  0.975047\n"
     ]
    }
   ],
   "source": [
    "dual_AP = train_and_test_dual_input(\"Laplacians + Abstract Persistence Images\", laplacians, abstract_persistence_images, selected_labels, (1000, 1000), (100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "# import labels for the shapes\n",
    "medical_shape_labels = np.genfromtxt('../FiltrationsForGNNs/Medical Dataset/shape_labels.csv', delimiter=',', skip_header=1)\n",
    "medical_shape_labels = medical_shape_labels.astype(int)[:,2]\n",
    "print(medical_shape_labels)\n",
    "print(len(medical_shape_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 50 samples.\n",
      "Shape of laplacians: (50, 1000, 1000)\n",
      "Shape of VR persistence images: (50, 100, 100)\n",
      "Shape of abstract persistence images: (50, 100, 100)\n",
      "Shape of selected labels: (50,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 50 # currently set to full dataset\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(len(medical_shape_labels), size=num_samples, replace=False)\n",
    "base = '../FiltrationsForGNNs/Medical Dataset/'\n",
    "# Select the corresponding data and labels\n",
    "medical_laplacians = []\n",
    "medical_vr_persistence_images = []\n",
    "medical_abstract_persistence_images = []\n",
    "medical_selected_labels = []\n",
    "\n",
    "for i in random_indices:\n",
    "    medical_laplacians.append(np.genfromtxt(f'{base}/shape_{i}_laplacian.csv', delimiter=',', skip_header=0))\n",
    "    medical_vr_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_vr_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_abstract_persistence_images.append(np.genfromtxt(f'{base}/shape_{i}_abstract_persistence_image.csv', delimiter=',', skip_header=0))\n",
    "    medical_selected_labels.append(medical_shape_labels[i])\n",
    "\n",
    "# Convert selected labels to NumPy array\n",
    "medical_selected_labels = np.array(medical_selected_labels)\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Randomly selected {num_samples} samples.\")\n",
    "print(f\"Shape of laplacians: {np.array(medical_laplacians).shape}\")\n",
    "print(f\"Shape of VR persistence images: {np.array(medical_vr_persistence_images).shape}\")\n",
    "print(f\"Shape of abstract persistence images: {np.array(medical_abstract_persistence_images).shape}\")\n",
    "print(f\"Shape of selected labels: {medical_selected_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical_selected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lap = ShapeDataset(medical_laplacians, medical_selected_labels)\n",
    "data_vr = ShapeDataset(medical_vr_persistence_images, medical_selected_labels)\n",
    "data_pi = ShapeDataset(medical_abstract_persistence_images, medical_selected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_single(model, data):\n",
    "    test_dataloader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "    epoch_results = []\n",
    "    # Testing step\n",
    "    test_loss, test_accuracy, precision, recall, f1 = test_single_input(model, device, test_dataloader, nn.CrossEntropyLoss())\n",
    "\n",
    "\n",
    "    # Storing results\n",
    "    epoch_results.append({\n",
    "    'Test Loss': test_loss,\n",
    "    'Test Accuracy (%)': test_accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    y = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = lap(data)  # Forward through the single-input model\n",
    "            _, predicted = output.max(1)\n",
    "            y.append(predicted)\n",
    "    return epoch_results_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results,output = validation_single(lap, data_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validation_dual(model, data1, data2, label):\n",
    "    dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data1]  # Shape [1, 100, 100]\n",
    "    dataset2 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in data2]  # Shape [1, 100, 100]\n",
    "    labels = torch.tensor(label, dtype=torch.long)\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.stack(dataset1), torch.stack(dataset2), labels\n",
    "    )\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    test_loss, test_accuracy, precision, recall, f1 = test_dual_input(dual_vr, device, test_dataloader, nn.CrossEntropyLoss())\n",
    "    epoch_results = []\n",
    "\n",
    "    # Storing results\n",
    "    epoch_results.append({\n",
    "        'Test Loss': test_loss,\n",
    "        'Test Accuracy (%)': test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    # Convert results to DataFrame for tabular output\n",
    "    epoch_results_df = pd.DataFrame(epoch_results)\n",
    "    y = []\n",
    "    with torch.no_grad():\n",
    "        for data1, data2, target in test_dataloader:\n",
    "            data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "            output = dual_vr(data1, data2)  # Forward through the dual-input model\n",
    "            _, predicted = output.max(1)\n",
    "            y.append(predicted)\n",
    "    return epoch_results_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 1000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in medical_laplacians]  # Shape [1, 100, 100]\n",
    "dataset1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test Loss  Test Accuracy (%)  Precision  Recall  F1 Score\n",
      "0   4.287778               32.0   0.661333    0.32  0.248539\n"
     ]
    }
   ],
   "source": [
    "dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in medical_laplacians]  # Shape [1, 100, 100]\n",
    "dataset2 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in medical_vr_persistence_images]  # Shape [1, 100, 100]\n",
    "labels = torch.tensor(medical_selected_labels, dtype=torch.long)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.stack(dataset1), torch.stack(dataset2), labels\n",
    "    )\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loss, test_accuracy, precision, recall, f1 = test_dual_input(dual_vr, device, test_dataloader, nn.CrossEntropyLoss())\n",
    "epoch_results = []\n",
    "\n",
    "# Storing results\n",
    "epoch_results.append({\n",
    "'Test Loss': test_loss,\n",
    "'Test Accuracy (%)': test_accuracy,\n",
    "'Precision': precision,\n",
    "'Recall': recall,\n",
    "'F1 Score': f1\n",
    "})\n",
    "\n",
    "# Convert results to DataFrame for tabular output\n",
    "epoch_results_df = pd.DataFrame(epoch_results)\n",
    "print(epoch_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 1, 1, 1, 1, 0, 1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "with torch.no_grad():\n",
    "        for data1, data2, target in test_dataloader:\n",
    "            data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "            output = dual_vr(data1, data2)  # Forward through the dual-input model\n",
    "            _, predicted = output.max(1)\n",
    "            y.append(predicted)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test Loss  Test Accuracy (%)  Precision  Recall  F1 Score\n",
      "0  19.548151               74.0     0.5476    0.74  0.629425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanp\\anaconda3\\envs\\FiltrationsForGNNs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "dataset1 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in medical_laplacians]  # Shape [1, 100, 100]\n",
    "dataset2 = [torch.tensor(d, dtype=torch.float32).unsqueeze(0) for d in medical_abstract_persistence_images]  # Shape [1, 100, 100]\n",
    "labels = torch.tensor(medical_selected_labels, dtype=torch.long)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.stack(dataset1), torch.stack(dataset2), labels\n",
    "    )\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loss, test_accuracy, precision, recall, f1 = test_dual_input(dual_AP, device, test_dataloader, nn.CrossEntropyLoss())\n",
    "epoch_results = []\n",
    "\n",
    "# Storing results\n",
    "epoch_results.append({\n",
    "'Test Loss': test_loss,\n",
    "'Test Accuracy (%)': test_accuracy,\n",
    "'Precision': precision,\n",
    "'Recall': recall,\n",
    "'F1 Score': f1\n",
    "})\n",
    "\n",
    "# Convert results to DataFrame for tabular output\n",
    "epoch_results_df = pd.DataFrame(epoch_results)\n",
    "print(epoch_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "with torch.no_grad():\n",
    "        for data1, data2, target in test_dataloader:\n",
    "            data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "            output = dual_AP(data1, data2)  # Forward through the dual-input model\n",
    "            _, predicted = output.max(1)\n",
    "            y.append(predicted)\n",
    "\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FiltrationsForGNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
