{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaY0lEQVR4nO3df2xV9f3H8dfl1xXx9hqC7b2F0nQE4rSMTEB+BPm12dBMNgQX1GQp/xgdP0ytSkSywfYHNW4Qs6BsMoKQweAf+ZFAxC7QImEshWBANKRIkTpaK0R6S2WXAJ/vH4T79VJEPpd7effePh/JTbz3njf34/HIk8O99zTgnHMCAMBAD+sFAAC6LyIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDM9LJewI2uXr2qM2fOKBQKKRAIWC8HAODJOaf29nYVFhaqR49bn+t0uQidOXNGRUVF1ssAANyhpqYmDRo06JbbdLm/jguFQtZLAACkwe38fp6xCL3zzjsqKSnRPffco5EjR+qjjz66rTn+Cg4AcsPt/H6ekQht3rxZlZWVWrx4sQ4fPqzHHntM5eXlOn36dCZeDgCQpQKZuIr2mDFj9Mgjj2jVqlWJx3784x9rxowZqq6uvuVsLBZTOBxO95IAAHdZW1ub8vLybrlN2s+ELl26pEOHDqmsrCzp8bKyMu3fv7/T9vF4XLFYLOkGAOge0h6hs2fP6sqVKyooKEh6vKCgQC0tLZ22r66uVjgcTtz4ZBwAdB8Z+2DCjW9IOedu+ibVokWL1NbWlrg1NTVlakkAgC4m7d8TGjBggHr27NnprKe1tbXT2ZEkBYNBBYPBdC8DAJAF0n4m1KdPH40cOVI1NTVJj9fU1Gj8+PHpfjkAQBbLyBUTqqqq9Jvf/EajRo3SuHHj9O677+r06dN64YUXMvFyAIAslZEIzZ49W+fOndMf//hHNTc3q7S0VDt37lRxcXEmXg4AkKUy8j2hO8H3hAAgN5h8TwgAgNtFhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMpD1CS5cuVSAQSLpFIpF0vwwAIAf0ysQv+vDDD+tf//pX4n7Pnj0z8TIAgCyXkQj16tWLsx8AwA/KyHtCDQ0NKiwsVElJiZ5++mmdPHnye7eNx+OKxWJJNwBA95D2CI0ZM0br16/Xrl27tHr1arW0tGj8+PE6d+7cTbevrq5WOBxO3IqKitK9JABAFxVwzrlMvkBHR4eGDBmihQsXqqqqqtPz8Xhc8Xg8cT8WixEiAMgBbW1tysvLu+U2GXlP6Lv69eun4cOHq6Gh4abPB4NBBYPBTC8DANAFZfx7QvF4XJ999pmi0WimXwoAkGXSHqFXXnlFdXV1amxs1H/+8x899dRTisViqqioSPdLAQCyXNr/Ou7LL7/UM888o7Nnz+qBBx7Q2LFjdeDAARUXF6f7pQAAWS7jH0zwFYvFFA6HrZeBDBk8eLD3zM9+9jPvmYkTJ3rP3E2BQMB7ZtasWd4zLS0t3jOSNGTIEO+Z+vp675lPP/3Ue+Zu+slPfuI98/XXX3vPTJs2zXsmG9zOBxO4dhwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYLmCJlqfyMqPfee8975uc//7n3zN0Ui8W8Z7766ivvmS72v6qZgQMHes/069cvAyu5uS+//NJ7Jld/ygAXMAUAdGlECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAw08t6AchePXv29J45ceLEXZnZuHGj94wkXblyxXvm66+/9p75/PPPvWdyUSpXzN+7d6/3TGlpqfeMdO0q0L7KyspSeq3uijMhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMwDnnrBfxXbFYLKWLGgKwNWHCBO+Zbdu2ec/cf//93jO7d+/2npGkl156yXvmk08+Sem1clFbW5vy8vJuuQ1nQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAmV7WCwDQ9aRyMdLt27d7z6RyseI9e/Z4z8yYMcN7RpI6OjpSmsPt40wIAGCGCAEAzHhHaO/evZo+fboKCwsVCAS0devWpOedc1q6dKkKCwvVt29fTZ48WceOHUvXegEAOcQ7Qh0dHRoxYoRWrlx50+fffPNNrVixQitXrlR9fb0ikYgef/xxtbe33/FiAQC5xfuDCeXl5SovL7/pc845vfXWW1q8eLFmzpwpSVq3bp0KCgq0ceNGPf/883e2WgBATknre0KNjY1qaWlRWVlZ4rFgMKhJkyZp//79N52Jx+OKxWJJNwBA95DWCLW0tEiSCgoKkh4vKChIPHej6upqhcPhxK2oqCidSwIAdGEZ+XRcIBBIuu+c6/TYdYsWLVJbW1vi1tTUlIklAQC6oLR+WTUSiUi6dkYUjUYTj7e2tnY6O7ouGAwqGAymcxkAgCyR1jOhkpISRSIR1dTUJB67dOmS6urqNH78+HS+FAAgB3ifCV24cEEnTpxI3G9sbNTHH3+s/v37a/DgwaqsrNSyZcs0dOhQDR06VMuWLdO9996rZ599Nq0LBwBkP+8IHTx4UFOmTEncr6qqkiRVVFTovffe08KFC3Xx4kXNnTtX33zzjcaMGaMPP/xQoVAofasGAOSEgHPOWS/iu2KxWEoXNQTQ2ZIlS1Kae/HFF71n7rvvPu+ZNWvWeM+89tpr3jN89cNGW1ub8vLybrkN144DAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAmbT+ZFUAmfO73/3Oe2bBggUpvdb999/vPbNt2zbvmblz53rPILdwJgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOECpoCBP//5z94zlZWV3jPOOe8ZSZo/f773zOrVq1N6LXRvnAkBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa4gClSdv/993vPhEIh75mzZ896z1y8eNF7RpJ69fL/X+IPf/iD90xVVZX3zKVLl7xn3n33Xe8ZSVq1alVKc4AvzoQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNcwBQp++ijj7xnHnroIe+ZI0eOeM/85S9/8Z6RpKeeesp7Ztq0aSm9lq+amhrvmRdffDEDKwHShzMhAIAZIgQAMOMdob1792r69OkqLCxUIBDQ1q1bk56fM2eOAoFA0m3s2LHpWi8AIId4R6ijo0MjRozQypUrv3ebadOmqbm5OXHbuXPnHS0SAJCbvD+YUF5ervLy8ltuEwwGFYlEUl4UAKB7yMh7QrW1tcrPz9ewYcP03HPPqbW19Xu3jcfjisViSTcAQPeQ9giVl5drw4YN2r17t5YvX676+npNnTpV8Xj8pttXV1crHA4nbkVFReleEgCgi0r794Rmz56d+OfS0lKNGjVKxcXF2rFjh2bOnNlp+0WLFqmqqipxPxaLESIA6CYy/mXVaDSq4uJiNTQ03PT5YDCoYDCY6WUAALqgjH9P6Ny5c2pqalI0Gs30SwEAsoz3mdCFCxd04sSJxP3GxkZ9/PHH6t+/v/r376+lS5dq1qxZikajOnXqlF5//XUNGDBATz75ZFoXDgDIft4ROnjwoKZMmZK4f/39nIqKCq1atUpHjx7V+vXrdf78eUWjUU2ZMkWbN29WKBRK36oBADkh4Jxz1ov4rlgspnA4bL0M3IaFCxd6z7zxxhsZWEn2CQQC3jNr1qzxnvnTn/7kPSNJx48fT2kO+K62tjbl5eXdchuuHQcAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzXEUbKevTp4/3TCo/3HDjxo3eM2PHjvWeuZtSuYp2Kv+rXrhwwXtGkt5++23vmb/97W/eM1988YX3DLIHV9EGAHRpRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZLmCKlPXo4f9nmIqKCu+Zv//9794zV69e9Z6RpE2bNnnPxGIx75lULmD605/+1Hvm0Ucf9Z5JVUdHh/fMwYMHvWdeeOEF75mGhgbvGSm1i8bi/3EBUwBAl0aEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOECpkjZE0884T2zbdu2DKyks/nz56c0t2rVqjSvJH1CoZD3zC9+8YuUXuuZZ57xnnnooYe8Z370ox95z6Riy5YtKc1t2LDhrr1WLuICpgCALo0IAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMFTJHShSclad++fd4zqfy33bNnj/fMtGnTvGck6fLlyynNQRo0aJD3zMKFC71nTp486T3z7LPPes9I0ieffOI9s3jxYu+Z5uZm75lswAVMAQBdGhECAJjxilB1dbVGjx6tUCik/Px8zZgxQ8ePH0/axjmnpUuXqrCwUH379tXkyZN17NixtC4aAJAbvCJUV1enefPm6cCBA6qpqdHly5dVVlamjo6OxDZvvvmmVqxYoZUrV6q+vl6RSESPP/642tvb0754AEB26+Wz8QcffJB0f+3atcrPz9ehQ4c0ceJEOef01ltvafHixZo5c6Ykad26dSooKNDGjRv1/PPPp2/lAICsd0fvCbW1tUmS+vfvL0lqbGxUS0uLysrKEtsEg0FNmjRJ+/fvv+mvEY/HFYvFkm4AgO4h5Qg551RVVaUJEyaotLRUktTS0iJJKigoSNq2oKAg8dyNqqurFQ6HE7eioqJUlwQAyDIpR2j+/Pk6cuSI/vnPf3Z6LhAIJN13znV67LpFixapra0tcWtqakp1SQCALOP1ntB1CxYs0Pbt27V3796kL6hFIhFJ186IotFo4vHW1tZOZ0fXBYNBBYPBVJYBAMhyXmdCzjnNnz9f77//vnbv3q2SkpKk50tKShSJRFRTU5N47NKlS6qrq9P48ePTs2IAQM7wOhOaN2+eNm7cqG3btikUCiXe5wmHw+rbt68CgYAqKyu1bNkyDR06VEOHDtWyZct07733pnzZDABA7vKK0KpVqyRJkydPTnp87dq1mjNnjqRr14K6ePGi5s6dq2+++UZjxozRhx9+qFAolJYFAwByBxcwzTH33Xef98y2bdtSeq0b/zByO7766ivvmQcffNB7ho/6A/a4gCkAoEsjQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAmZR+siq6rtdff917JpWrYUvS+fPnvWd+/etfe89wRWwgd3EmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QKmXdhLL73kPfPqq696zxw9etR7RpImTpzoPcPFSAF8F2dCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZLmB6l/zyl7/0nvn973/vPXPw4EHvmVmzZnnPSFyMFMCd40wIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDBUzvklWrVnnPfP75594zr776qvfMmTNnvGcAIB04EwIAmCFCAAAzXhGqrq7W6NGjFQqFlJ+frxkzZuj48eNJ28yZM0eBQCDpNnbs2LQuGgCQG7wiVFdXp3nz5unAgQOqqanR5cuXVVZWpo6OjqTtpk2bpubm5sRt586daV00ACA3eH0w4YMPPki6v3btWuXn5+vQoUOaOHFi4vFgMKhIJJKeFQIActYdvSfU1tYmSerfv3/S47W1tcrPz9ewYcP03HPPqbW19Xt/jXg8rlgslnQDAHQPKUfIOaeqqipNmDBBpaWlicfLy8u1YcMG7d69W8uXL1d9fb2mTp2qeDx+01+nurpa4XA4cSsqKkp1SQCALBNwzrlUBufNm6cdO3Zo3759GjRo0Pdu19zcrOLiYm3atEkzZ87s9Hw8Hk8KVCwWy8kQ/fe///WeaW5u9p6prKz0ntm3b5/3DAD8kLa2NuXl5d1ym5S+rLpgwQJt375de/fuvWWAJCkajaq4uFgNDQ03fT4YDCoYDKayDABAlvOKkHNOCxYs0JYtW1RbW6uSkpIfnDl37pyampoUjUZTXiQAIDd5vSc0b948/eMf/9DGjRsVCoXU0tKilpYWXbx4UZJ04cIFvfLKK/r3v/+tU6dOqba2VtOnT9eAAQP05JNPZuRfAACQvbzOhK5f/2zy5MlJj69du1Zz5sxRz549dfToUa1fv17nz59XNBrVlClTtHnzZoVCobQtGgCQG7z/Ou5W+vbtq127dt3RggAA3QdX0b5LBg4caL0EAOhyuIApAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZrpchJxz1ksAAKTB7fx+3uUi1N7ebr0EAEAa3M7v5wHXxU49rl69qjNnzigUCikQCCQ9F4vFVFRUpKamJuXl5Rmt0B774Rr2wzXsh2vYD9d0hf3gnFN7e7sKCwvVo8etz3V63aU13bYePXpo0KBBt9wmLy+vWx9k17EfrmE/XMN+uIb9cI31fgiHw7e1XZf76zgAQPdBhAAAZrIqQsFgUEuWLFEwGLReiin2wzXsh2vYD9ewH67Jtv3Q5T6YAADoPrLqTAgAkFuIEADADBECAJghQgAAM1kVoXfeeUclJSW65557NHLkSH300UfWS7qrli5dqkAgkHSLRCLWy8q4vXv3avr06SosLFQgENDWrVuTnnfOaenSpSosLFTfvn01efJkHTt2zGaxGfRD+2HOnDmdjo+xY8faLDZDqqurNXr0aIVCIeXn52vGjBk6fvx40jbd4Xi4nf2QLcdD1kRo8+bNqqys1OLFi3X48GE99thjKi8v1+nTp62Xdlc9/PDDam5uTtyOHj1qvaSM6+jo0IgRI7Ry5cqbPv/mm29qxYoVWrlyperr6xWJRPT444/n3HUIf2g/SNK0adOSjo+dO3fexRVmXl1dnebNm6cDBw6opqZGly9fVllZmTo6OhLbdIfj4Xb2g5Qlx4PLEo8++qh74YUXkh578MEH3WuvvWa0ortvyZIlbsSIEdbLMCXJbdmyJXH/6tWrLhKJuDfeeCPx2P/+9z8XDofdX//6V4MV3h037gfnnKuoqHC/+tWvTNZjpbW11UlydXV1zrnuezzcuB+cy57jISvOhC5duqRDhw6prKws6fGysjLt37/faFU2GhoaVFhYqJKSEj399NM6efKk9ZJMNTY2qqWlJenYCAaDmjRpUrc7NiSptrZW+fn5GjZsmJ577jm1trZaLymj2traJEn9+/eX1H2Phxv3w3XZcDxkRYTOnj2rK1euqKCgIOnxgoICtbS0GK3q7hszZozWr1+vXbt2afXq1WppadH48eN17tw566WZuf7fv7sfG5JUXl6uDRs2aPfu3Vq+fLnq6+s1depUxeNx66VlhHNOVVVVmjBhgkpLSyV1z+PhZvtByp7joctdRftWbvzRDs65To/lsvLy8sQ/Dx8+XOPGjdOQIUO0bt06VVVVGa7MXnc/NiRp9uzZiX8uLS3VqFGjVFxcrB07dmjmzJmGK8uM+fPn68iRI9q3b1+n57rT8fB9+yFbjoesOBMaMGCAevbs2elPMq2trZ3+xNOd9OvXT8OHD1dDQ4P1Usxc/3Qgx0Zn0WhUxcXFOXl8LFiwQNu3b9eePXuSfvRLdzsevm8/3ExXPR6yIkJ9+vTRyJEjVVNTk/R4TU2Nxo8fb7Qqe/F4XJ999pmi0aj1UsyUlJQoEokkHRuXLl1SXV1dtz42JOncuXNqamrKqePDOaf58+fr/fff1+7du1VSUpL0fHc5Hn5oP9xMlz0eDD8U4WXTpk2ud+/ebs2aNe7TTz91lZWVrl+/fu7UqVPWS7trXn75ZVdbW+tOnjzpDhw44J544gkXCoVyfh+0t7e7w4cPu8OHDztJbsWKFe7w4cPuiy++cM4598Ybb7hwOOzef/99d/ToUffMM8+4aDTqYrGY8crT61b7ob293b388stu//79rrGx0e3Zs8eNGzfODRw4MKf2w29/+1sXDoddbW2ta25uTty+/fbbxDbd4Xj4of2QTcdD1kTIOefefvttV1xc7Pr06eMeeeSRpI8jdgezZ8920WjU9e7d2xUWFrqZM2e6Y8eOWS8r4/bs2eMkdbpVVFQ45659LHfJkiUuEom4YDDoJk6c6I4ePWq76Ay41X749ttvXVlZmXvggQdc79693eDBg11FRYU7ffq09bLT6mb//pLc2rVrE9t0h+Phh/ZDNh0P/CgHAICZrHhPCACQm4gQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM/8HwJMx17oCspAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ac23c427f64ed2842e0fa27c03477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tr/3zw9td7531z0_hhwc8105rv00000gn/T/ipykernel_95870/2730739436.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3140, Accuracy: 9060/10000 (91%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eee0bf44c7a4f449c0113c0e7b82ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2041, Accuracy: 9411/10000 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b9e3ce652b460eb879dc47b5768a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1739, Accuracy: 9490/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tr/3zw9td7531z0_hhwc8105rv00000gn/T/ipykernel_95870/2730739436.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
